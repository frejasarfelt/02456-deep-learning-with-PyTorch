{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAva8TnYFtFu"
      },
      "source": [
        "# Contents and why we need this lab\n",
        "\n",
        "This lab is about implementing neural networks yourself before we start using other frameworks that hide some of the computation from you. It builds on the first lab, where you derived the equations for neural network forward and backward propagation and gradient descent parameter updates. \n",
        "\n",
        "All the frameworks for deep learning you will meet from now on use automatic differentiation (autodiff), so you do not have to code the backward step yourself. In this version of this lab, you will develop your own autodif implementation. We also have an optional [version](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/2_Feedforward_Python/2.2-FNN-NumPy.ipynb) of this lab where you have to code the backward pass explicitly in Numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCa7HzwpFtFy"
      },
      "source": [
        "# External sources of information\n",
        "\n",
        "1. Jupyter notebook. You can find more information about Jupyter notebooks [here](https://jupyter.org/). It will come as part of the [Anaconda](https://www.anaconda.com/) Python installation. \n",
        "2. [NumPy](https://numpy.org/). Part of Anaconda distribution.  If you already know how to program, most things about Python and NumPy can be found with Google searches.\n",
        "3. [Nanograd](https://github.com/rasmusbergpalm/nanograd) is a minimalistic version of autodiff developed by Rasmus Berg Palm that we use for our framework.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SjiIp-TFtF0"
      },
      "source": [
        "# This notebook will follow the next steps:\n",
        "\n",
        "1. Nanograd automatic differentiation framework\n",
        "2. Finite difference method\n",
        "3. Data generation\n",
        "4. Defining and initializing the network\n",
        "5. Forward pass\n",
        "6. Training loop \n",
        "7. Testing your model\n",
        "8. Further extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyXeAA-HuT7s"
      },
      "source": [
        "# Nanograd automatic differention framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6UWKCLKubgA"
      },
      "source": [
        "The [Nanograd](https://github.com/rasmusbergpalm/nanograd) framework defines a class Var which both holds a value and gradient value that we can use to store the intermediate values when we apply the chain rule of differentiation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jd4CoEBNzNWS"
      },
      "outputs": [],
      "source": [
        "# Copy and pasted from https://github.com/rasmusbergpalm/nanograd/blob/3a1bf9e9e724da813bfccf91a6f309abdade9f39/nanograd.py\n",
        "\n",
        "from math import exp, log\n",
        "\n",
        "class Var:\n",
        "    \"\"\"\n",
        "    A variable which holds a float and enables gradient computations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, val: float, grad_fn=lambda: []):\n",
        "        assert type(val) == float\n",
        "        self.v = val\n",
        "        self.grad_fn = grad_fn\n",
        "        self.grad = 0.0\n",
        "\n",
        "    def backprop(self, bp):\n",
        "        self.grad += bp\n",
        "        for input, grad in self.grad_fn():\n",
        "            input.backprop(grad * bp)\n",
        "\n",
        "    def backward(self):\n",
        "        self.backprop(1.0)\n",
        "\n",
        "    def __add__(self: 'Var', other: 'Var') -> 'Var':\n",
        "        return Var(self.v + other.v, lambda: [(self, 1.0), (other, 1.0)])\n",
        "\n",
        "    def __mul__(self: 'Var', other: 'Var') -> 'Var':\n",
        "        return Var(self.v * other.v, lambda: [(self, other.v), (other, self.v)])\n",
        "\n",
        "    def __pow__(self, power):\n",
        "        assert type(power) in {float, int}, \"power must be float or int\"\n",
        "        return Var(self.v ** power, lambda: [(self, power * self.v ** (power - 1))])\n",
        "\n",
        "    def __neg__(self: 'Var') -> 'Var':\n",
        "        return Var(-1.0) * self\n",
        "\n",
        "    def __sub__(self: 'Var', other: 'Var') -> 'Var':\n",
        "        return self + (-other)\n",
        "\n",
        "    def __truediv__(self: 'Var', other: 'Var') -> 'Var':\n",
        "        return self * other ** -1\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Var(v=%.4f, grad=%.4f)\" % (self.v, self.grad)\n",
        "\n",
        "    def relu(self):\n",
        "        return Var(self.v if self.v > 0.0 else 0.0, lambda: [(self, 1.0 if self.v > 0.0 else 0.0)])\n",
        "\n",
        "    def identity(self):\n",
        "        return Var(self.v, lambda: [(self, 1.0)])\n",
        "\n",
        "    def tanh(self):\n",
        "        return Var(2/(1+exp(-2*self.v)), lambda: [(self, 1.0)])\n",
        "\n",
        "    def sigmoid(self):\n",
        "        return Var(1/(1.0+exp(-self.v)), lambda: [(self, 1.0)])\n",
        "\n",
        "    def exp(self):\n",
        "        return Var(exp(self.v), lambda: [(self, exp(self.v))])\n",
        "\n",
        "    def log(self):\n",
        "        return Var(log(self.v), lambda: [(self, self.v ** -1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDX67D6jzcte"
      },
      "source": [
        "A few examples illustrate how we can use this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk6PeLc3zwPT",
        "outputId": "e8aa29db-0501-4e88-878a-5222c65cb469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(v=3.0000, grad=5.0000)\n",
            "Var(v=5.0000, grad=3.0000)\n",
            "Var(v=15.0000, grad=1.0000)\n"
          ]
        }
      ],
      "source": [
        "a = Var(3.0)\n",
        "b = Var(5.0)\n",
        "f = a * b\n",
        "\n",
        "f.backward()\n",
        "\n",
        "for v in [a, b, f]:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmKhYgsY0g_o",
        "outputId": "62b1b654-e6fe-4921-d37b-3e87cfe67483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(v=3.0000, grad=14.0000)\n",
            "Var(v=5.0000, grad=3.0000)\n",
            "Var(v=15.0000, grad=1.0000)\n",
            "Var(v=9.0000, grad=3.0000)\n",
            "Var(v=27.0000, grad=1.0000)\n",
            "Var(v=42.0000, grad=1.0000)\n"
          ]
        }
      ],
      "source": [
        "a = Var(3.0)\n",
        "b = Var(5.0)\n",
        "c = a * b\n",
        "d = Var(9.0)\n",
        "e = a * d\n",
        "f = c + e\n",
        "\n",
        "f.backward()\n",
        "\n",
        "for v in [a, b, c, d, e, f]:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe3B6uEH140p"
      },
      "source": [
        "## Exercise a) What is being calculated?\n",
        "\n",
        "Explain briefly the output of the code? What is the expression we differentiate and with respect to what variables?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the output?**  \n",
        "The output *v* is the value of the variable.  \n",
        "The output *grad* is the gradient calculated with the function *f.backward*, which uses the function *backprop()* with input 1. The variable *f* depends on all the other variables, and therefore all *grads* are being updated when this function is run. *a,b,d* are multiplied with one another and therefore their gradients are updated depending on one another. *c,e,f* are either added with another value or nothing is done. By doing this the gradient will only become 1.\n",
        "\n",
        "**What is the expression?**  \n",
        "differentiate?"
      ],
      "metadata": {
        "id": "zT13lXrfbOoh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8_Q0t2I3Ruj"
      },
      "source": [
        "## Exercise b) How does the backward function work?\n",
        "\n",
        "You need to understand how the backward function calculates the gradients. We can use the two examples above to help with that.\n",
        "\n",
        "Go through the following four steps and answer the questions on the way:\n",
        "\n",
        "1. We represent the two expressions as graphs as shown below. Fill in the missing expressions for the different derivatives.\n",
        "\n",
        "2. In the remainder consider the first expression. Make a schematic of the data structure which is generated when we define the expression for f. \n",
        "\n",
        "3. Then execute the backward function by hand to convince yourself that it indeed calculates the gradients with respect to the variables. \n",
        "\n",
        "4. Write down the sequence of calls to backprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "idGr71jYXl26"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "import graphviz\n",
        "\n",
        "#logging.basicConfig(format='[%(levelname)s@%(name)s] %(message)s', level=logging.DEBUG)\n",
        "\n",
        "#graphviz.__version__, graphviz.version()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "KPe30Q2QXzeG",
        "outputId": "a354b6bd-491e-4649-c0a5-be6d5006245c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd4571687d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: first expression Pages: 1 -->\n<svg width=\"162pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 162.00 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>first expression</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 158,-94 158,4 -4,4\"/>\n<!-- a -->\n<g id=\"node1\" class=\"node\">\n<title>a</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"18\" cy=\"-72\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">a</text>\n</g>\n<!-- f -->\n<g id=\"node2\" class=\"node\">\n<title>f</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"136\" cy=\"-45\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"136\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">f</text>\n</g>\n<!-- a&#45;&gt;f -->\n<g id=\"edge1\" class=\"edge\">\n<title>a&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M35.6658,-67.9578C54.8698,-63.5637 85.8151,-56.483 108.2661,-51.3459\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.2461,-54.7122 118.2134,-49.0698 107.6847,-47.8885 109.2461,-54.7122\"/>\n<text text-anchor=\"middle\" x=\"77\" y=\"-66.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">df/da=b</text>\n</g>\n<!-- b -->\n<g id=\"node3\" class=\"node\">\n<title>b</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b</text>\n</g>\n<!-- b&#45;&gt;f -->\n<g id=\"edge2\" class=\"edge\">\n<title>b&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M36.0339,-20.9637C52.7278,-23.8381 78.1872,-28.555 100,-34 103.0098,-34.7513 106.1413,-35.6022 109.2457,-36.4899\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.3051,-39.8618 118.8887,-39.3744 110.3112,-33.1554 108.3051,-39.8618\"/>\n<text text-anchor=\"middle\" x=\"77\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">df/db=a</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "e1 = graphviz.Digraph('first expression', filename='fsm.gv')\n",
        "\n",
        "e1.attr(rankdir='LR', size='8,5')\n",
        "\n",
        "e1.attr('node', shape='circle')\n",
        "e1.edge('a', 'f', label='df/da=b')\n",
        "e1.edge('b', 'f', label='df/db=a')\n",
        "\n",
        "e1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Schematic of the data structure:\n",
        "\n",
        "**a**:  \n",
        "a.v = 3 and a.grad_fn = [ ]\n",
        "\n",
        "**b**:  \n",
        "b.v = 5 and b.grad_fn = [ ]\n",
        "\n",
        "**f**:  \n",
        "$f.v = a.v*b.v = 3*5 = 15$  \n",
        "$f.grad_{fn} = [(a, b.v), (b, a.v)] = [(a,5), (b,3)]$"
      ],
      "metadata": {
        "id": "vVYTAqgeo5hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backward function by hand\n",
        "\n",
        "The function calls the function backprop with input bp=1.  \n",
        "The backprop function takes the current gradient (f.grad=0) and adds with bp. Now the gradient is updated to f.grad=1.  \n",
        "\n",
        "Then we loop through the f.grad_fn which is a list with tuples. Each loop will iterate over one tuple. First loop will then have input=a and grad=5. Then we update the a.backprop($5*1$). Next loop is input=b and grad=3, where b.backprop($3*1$).\n",
        "\n",
        "\n",
        "So by calculating f.backward, which is dependent of the variables a and b, we actually calculate the gradients of all three variables."
      ],
      "metadata": {
        "id": "m_fhwpQIrWL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence of calls to backprop\n",
        "\n",
        "These are the sequences of calls to backprop that is done when f.backward is run.  \n",
        "f.backprop(1)  \n",
        "a.backprop(5)  \n",
        "b.backprop(3)"
      ],
      "metadata": {
        "id": "SUM--J4xxg4Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "0nittR-mZFeX",
        "outputId": "505c5c6e-9cc9-4627-d4c0-3d8b8d346883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd45712e390>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: second expression Pages: 1 -->\n<svg width=\"281pt\" height=\"158pt\"\n viewBox=\"0.00 0.00 281.00 158.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 154)\">\n<title>second expression</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-154 277,-154 277,4 -4,4\"/>\n<!-- a -->\n<g id=\"node1\" class=\"node\">\n<title>a</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"18\" cy=\"-75\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-71.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">a</text>\n</g>\n<!-- c -->\n<g id=\"node2\" class=\"node\">\n<title>c</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"137\" cy=\"-102\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137\" y=\"-98.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">c</text>\n</g>\n<!-- a&#45;&gt;c -->\n<g id=\"edge1\" class=\"edge\">\n<title>a&#45;&gt;c</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M35.5589,-78.9839C55.0696,-83.4108 86.8223,-90.6151 109.6075,-95.7849\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"108.8425,-99.2002 119.3691,-97.9997 110.3914,-92.3737 108.8425,-99.2002\"/>\n<text text-anchor=\"middle\" x=\"77.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dc/da=b</text>\n</g>\n<!-- e -->\n<g id=\"node4\" class=\"node\">\n<title>e</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"137\" cy=\"-48\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"137\" y=\"-44.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">e</text>\n</g>\n<!-- a&#45;&gt;e -->\n<g id=\"edge3\" class=\"edge\">\n<title>a&#45;&gt;e</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M35.1093,-69.3663C41.0519,-67.518 47.7844,-65.5441 54,-64 72.2255,-59.4724 92.9698,-55.4733 109.1606,-52.6056\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.8139,-56.0446 119.0705,-50.8903 108.62,-49.1472 109.8139,-56.0446\"/>\n<text text-anchor=\"middle\" x=\"77.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">de/da=d</text>\n</g>\n<!-- f -->\n<g id=\"node6\" class=\"node\">\n<title>f</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"255\" cy=\"-75\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"255\" y=\"-71.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">f</text>\n</g>\n<!-- c&#45;&gt;f -->\n<g id=\"edge5\" class=\"edge\">\n<title>c&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M154.6658,-97.9578C173.8698,-93.5637 204.8151,-86.483 227.2661,-81.3459\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.2461,-84.7122 237.2134,-79.0698 226.6847,-77.8885 228.2461,-84.7122\"/>\n<text text-anchor=\"middle\" x=\"196\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">df/dc=1</text>\n</g>\n<!-- b -->\n<g id=\"node3\" class=\"node\">\n<title>b</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"18\" cy=\"-132\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-128.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b</text>\n</g>\n<!-- b&#45;&gt;c -->\n<g id=\"edge2\" class=\"edge\">\n<title>b&#45;&gt;c</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M35.5589,-127.5734C55.0696,-122.6547 86.8223,-114.6498 109.6075,-108.9057\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.5281,-112.2832 119.3691,-106.4448 108.8169,-105.4955 110.5281,-112.2832\"/>\n<text text-anchor=\"middle\" x=\"77.5\" y=\"-125.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dc/db=a</text>\n</g>\n<!-- e&#45;&gt;f -->\n<g id=\"edge6\" class=\"edge\">\n<title>e&#45;&gt;f</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M155.0339,-50.9637C171.7278,-53.8381 197.1872,-58.555 219,-64 222.0098,-64.7513 225.1413,-65.6022 228.2457,-66.4899\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"227.3051,-69.8618 237.8887,-69.3744 229.3112,-63.1554 227.3051,-69.8618\"/>\n<text text-anchor=\"middle\" x=\"196\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">df/de=1</text>\n</g>\n<!-- d -->\n<g id=\"node5\" class=\"node\">\n<title>d</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"18\" cy=\"-18\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"18\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">d</text>\n</g>\n<!-- d&#45;&gt;e -->\n<g id=\"edge4\" class=\"edge\">\n<title>d&#45;&gt;e</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M35.9889,-20.9104C52.9226,-23.8318 78.9119,-28.785 101,-35 104.0364,-35.8544 107.1845,-36.8389 110.2985,-37.8758\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.3565,-41.2547 119.9514,-41.2723 111.68,-34.6515 109.3565,-41.2547\"/>\n<text text-anchor=\"middle\" x=\"77.5\" y=\"-38.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">de/dd=a</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "e2 = graphviz.Digraph('second expression', filename='fsm.gv')\n",
        "\n",
        "e2.attr(rankdir='LR', size='8,5')\n",
        "\n",
        "e2.attr('node', shape='circle')\n",
        "e2.edge('a', 'c', label='dc/da=b')\n",
        "e2.edge('b', 'c', label='dc/db=a')\n",
        "e2.edge('a', 'e', label='de/da=d')\n",
        "e2.edge('d', 'e', label='de/dd=a')\n",
        "e2.edge('c', 'f', label='df/dc=1')\n",
        "e2.edge('e', 'f', label='df/de=1')\n",
        "\n",
        "e2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5oi21W4gpeM"
      },
      "source": [
        "## Exercise c) What happens if we run backward again?\n",
        "\n",
        "Try to execute the code below. Explain what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtpJyr-gyX1",
        "outputId": "ade674ba-f3be-4510-ec61-f6ad4df6cb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(v=3.0000, grad=28.0000)\n",
            "Var(v=5.0000, grad=6.0000)\n",
            "Var(v=15.0000, grad=2.0000)\n",
            "Var(v=9.0000, grad=6.0000)\n",
            "Var(v=27.0000, grad=2.0000)\n",
            "Var(v=42.0000, grad=2.0000)\n"
          ]
        }
      ],
      "source": [
        "f.backward()\n",
        "\n",
        "for v in [a, b, c, d, e, f]:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we execute once again the gradient is already defined (not 0) from before. Therefore a new run will add the values once again to backprop and the values will add up.  \n",
        "That is why we see the values are double the size of before."
      ],
      "metadata": {
        "id": "WSTmJJyMygsa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8bPVq2VhsP-"
      },
      "source": [
        "## Exercise d) Zero gradient\n",
        "\n",
        "We can zero the gradient by backpropagating a -1.0 as is shown in the example below. (If you have run backward multiple time then you also have to run the cell below an equal amount of times.) Explain what is going on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnyPDQx9lJe0",
        "outputId": "ee37983e-79f5-4c91-aea6-cf2c8ac6f1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(v=2.0000, grad=0.0000)\n",
            "Var(v=5.0000, grad=6.0000)\n",
            "Var(v=15.0000, grad=2.0000)\n",
            "Var(v=9.0000, grad=6.0000)\n",
            "Var(v=27.0000, grad=2.0000)\n",
            "Var(v=42.0000, grad=2.0000)\n",
            "Var(v=2.0000, grad=0.0000)\n",
            "Var(v=5.0000, grad=3.0000)\n",
            "Var(v=15.0000, grad=1.0000)\n",
            "Var(v=9.0000, grad=3.0000)\n",
            "Var(v=27.0000, grad=1.0000)\n",
            "Var(v=42.0000, grad=1.0000)\n"
          ]
        }
      ],
      "source": [
        "a = Var(2.0)\n",
        "\n",
        "for v in [a, b, c, d, e, f]:\n",
        "    print(v)\n",
        "\n",
        "f.backprop(-1.0)\n",
        "\n",
        "for v in [a, b, c, d, e, f]:\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By setting bp=-1 the f.grad is updated from 1 to 0.  \n",
        "Furhtermore, the calculation of a.grad and b.grad will be the opposite gradient of before. This is why we will achieve 0 again. "
      ],
      "metadata": {
        "id": "xumg0Um10VJS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4057_ljNvWB"
      },
      "source": [
        "## Exercise e) Test correctness of derivatives with the finite difference method\n",
        "\n",
        "Write a small function that uses [the finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method) to numerically test that backpropation implementation is working. In short we will use\n",
        "$$\n",
        "\\frac{\\partial f(a)}{\\partial a} \\approx \\frac{f(a+da)-f(a)}{da}\n",
        "$$\n",
        "for $da \\ll 1$.\n",
        "\n",
        "As an example, we could approximate the derivative of the function $f(a)=a^2$ in e.g. the value $a=4$ using the finite difference method. This amounts to inserting the relevant values and approximating the gradient $f'(4)$ with the fraction above. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TGil92lSXDN",
        "outputId": "d4c89e97-c197-41dc-ac11-6154ea7afcc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(v=3.0000, grad=5.0000)\n",
            "Var(v=5.0000, grad=3.0000)\n",
            "Var(v=15.0000, grad=1.0000)\n",
            "5.000000413701855\n"
          ]
        }
      ],
      "source": [
        "# f function - try to change the code to test other types of functions as well (such as different polynomials etc.)\n",
        "def f_function(a):\n",
        "  a = Var(a)\n",
        "  b = Var(5.0)\n",
        "  f = a * b\n",
        "  f.backward()\n",
        "  return a,b,f\n",
        "\n",
        "for v in f_function(3.0):\n",
        "  print(v)\n",
        "\n",
        "# Insert your finite difference code here\n",
        "def finite_difference(da=1e-10):\n",
        "    \"\"\"\n",
        "    This function compute the finite difference between\n",
        "    \n",
        "    Input:\n",
        "    da:          The finite difference                           (float)\n",
        "    \n",
        "    Output:\n",
        "    finite_difference: numerical approximation to the derivative (float) \n",
        "    \"\"\"\n",
        "    \n",
        "    fa_da = f_function(3.0 + da)[2].v           # <- Insert correct expression\n",
        "    fa = f_function(3.0)[2].v               # <- Insert correct expression\n",
        "\n",
        "    finite_difference = (fa_da - fa) / da\n",
        "    \n",
        "    return finite_difference\n",
        "\n",
        "print(finite_difference())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pZar5RKaUkg"
      },
      "source": [
        "# Create an artificial dataset to play with\n",
        "\n",
        "We create a non-linear 1d regression task. The generator supports various noise levels and it creates train, validation and test sets. You can modify it yourself if you want more or less challenging tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y6yfMAQ8aduj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4YabfD43ajNh"
      },
      "outputs": [],
      "source": [
        "def data_generator(noise=0.1, n_samples=300, D1=True):\n",
        "    # Create covariates and response variable\n",
        "    if D1:\n",
        "        X = np.linspace(-3, 3, num=n_samples).reshape(-1,1) # 1-D\n",
        "        np.random.shuffle(X)\n",
        "        y = np.random.normal((0.5*np.sin(X[:,0]*3) + X[:,0]), noise) # 1-D with trend\n",
        "    else:\n",
        "        X = np.random.multivariate_normal(np.zeros(3), noise*np.eye(3), size = n_samples) # 3-D\n",
        "        np.random.shuffle(X)    \n",
        "        y = np.sin(X[:,0]) - 5*(X[:,1]**2) + 0.5*X[:,2] # 3-D\n",
        "\n",
        "    # Stack them together vertically to split data set\n",
        "    data_set = np.vstack((X.T,y)).T\n",
        "    \n",
        "    train, validation, test = np.split(data_set, [int(0.35*n_samples), int(0.7*n_samples)], axis=0)\n",
        "    \n",
        "    # Standardization of the data, remember we do the standardization with the training set mean and standard deviation\n",
        "    train_mu = np.mean(train, axis=0)\n",
        "    train_sigma = np.std(train, axis=0)\n",
        "    \n",
        "    train = (train-train_mu)/train_sigma\n",
        "    validation = (validation-train_mu)/train_sigma\n",
        "    test = (test-train_mu)/train_sigma\n",
        "    \n",
        "    x_train, x_validation, x_test = train[:,:-1], validation[:,:-1], test[:,:-1]\n",
        "    y_train, y_validation, y_test = train[:,-1], validation[:,-1], test[:,-1]\n",
        "\n",
        "    return x_train, y_train,  x_validation, y_validation, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u1oDngHLapIz"
      },
      "outputs": [],
      "source": [
        "D1 = True\n",
        "x_train, y_train,  x_validation, y_validation, x_test, y_test = data_generator(noise=0.5, D1=D1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Ysfa3FsBavlm",
        "outputId": "161de78b-845b-4174-d39d-fbbdbd4bfbdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "if D1:\n",
        "    plt.scatter(x_train[:,0], y_train);\n",
        "    plt.scatter(x_validation[:,0], y_validation);\n",
        "    plt.scatter(x_test[:,0], y_test);\n",
        "else:\n",
        "    plt.scatter(x_train[:,1], y_train);\n",
        "    plt.scatter(x_validation[:,1], y_validation);\n",
        "    plt.scatter(x_test[:,1], y_test);\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zac2HHNlgbpm"
      },
      "outputs": [],
      "source": [
        "# convert from nparray to Var\n",
        "def nparray_to_Var(x):\n",
        "  if x.ndim==1:\n",
        "    y = [[Var(float(x[i]))] for i in range(x.shape[0])] # always work with list of list\n",
        "  else:\n",
        "    y = [[Var(float(x[i,j])) for j in range(x.shape[1])] for i in range(x.shape[0])]\n",
        "  return y\n",
        "   \n",
        "x_train = nparray_to_Var(x_train)\n",
        "y_train = nparray_to_Var(y_train)\n",
        "x_validation = nparray_to_Var(x_validation)\n",
        "y_validation = nparray_to_Var(y_validation)\n",
        "x_test = nparray_to_Var(x_test)\n",
        "y_test = nparray_to_Var(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbjrqcpVFtGe"
      },
      "source": [
        "# Defining and initializing the network\n",
        "\n",
        "The steps to create a feed forward neural network are the following:\n",
        "\n",
        "1. **Number of hidden layer and hidden units**. We have to define the number of hidden units in each layer. The number of features in X and the output dimensionality (the size of Y) are given but the numbers in between are set by the researcher. Remember that for each unit in each layer beside in the input has a bias term.\n",
        "2. **Activation functions** for each hidden layer. Each hidden layer in your list must have an activation function (it can also be the linear activation which is equivalent to identity function). The power of neural networks comes from non-linear activation functions that learn representations (features) from the data allowing us to learn from it. \n",
        "3. **Parameter initialization**. We will initialize the weights to have random values. This is done in practice by drawing pseudo random numbers from a Gaussian or uniform distribution. It turns out that for deeper models we have to be careful about how we scale the random numbers. This will be the topic of the exercise below. For now we will just use unit variance Gaussians.  \n",
        "\n",
        "In order to make life easier for ourselves we define a DenseLayer class that takes care of initialization and the forward pass. We can also extend it later with print and advanced initialization capabilities. For the latter we have introduced a Initializer class.\n",
        "\n",
        "Note that we use Sequence in the code below. A Sequence is an ordered list. This means the order we insert and access items are the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ij_ieRsAt7Xt"
      },
      "outputs": [],
      "source": [
        "class Initializer:\n",
        "\n",
        "  def init_weights(self, n_in, n_out):\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def init_bias(self, n_out):\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eb18N5phuIha"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class NormalInitializer(Initializer):\n",
        "\n",
        "  def __init__(self, mean=0, std=0.1):\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "\n",
        "  def init_weights(self, n_in, n_out):\n",
        "    return [[Var(random.gauss(self.mean, self.std)) for _ in range(n_out)] for _ in range(n_in)]\n",
        "\n",
        "  def init_bias(self, n_out):\n",
        "    return [Var(0.0) for _ in range(n_out)]\n",
        "\n",
        "class ConstantInitializer(Initializer):\n",
        "\n",
        "  def __init__(self, weight=1.0, bias=0.0):\n",
        "    self.weight = weight\n",
        "    self.bias = bias\n",
        "\n",
        "  def init_weights(self, n_in, n_out):\n",
        "    return [[Var(self.weight) for _ in range(n_out)] for _ in range(n_in)]\n",
        "\n",
        "  def init_bias(self, n_out):\n",
        "    return [Var(self.bias) for _ in range(n_out)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jOLYGnZKuM6W"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "class DenseLayer:\n",
        "    def __init__(self, n_in: int, n_out: int, act_fn, initializer = NormalInitializer()):\n",
        "        self.weights = initializer.init_weights(n_in, n_out)\n",
        "        self.bias = initializer.init_bias(n_out)\n",
        "        self.act_fn = act_fn\n",
        "    \n",
        "    def __repr__(self):    \n",
        "        return 'Weights: ' + repr(self.weights) + ' Biases: ' + repr(self.bias)\n",
        "\n",
        "    def parameters(self) -> Sequence[Var]:\n",
        "      params = []\n",
        "      for r in self.weights:\n",
        "        params += r\n",
        "\n",
        "      return params + self.bias\n",
        "\n",
        "    def forward(self, single_input: Sequence[Var]) -> Sequence[Var]:\n",
        "        # self.weights is a matrix with dimension n_in x n_out. We check that the dimensionality of the input \n",
        "        # to the current layer matches the number of nodes in the current layer\n",
        "        assert len(self.weights) == len(single_input), \"weights and single_input must match in first dimension\"\n",
        "        weights = self.weights\n",
        "        out = []\n",
        "        # For some given data point single_input, we now want to calculate the resulting value in each node in the current layer\n",
        "        # We therefore loop over the (number of) nodes in the current layer:\n",
        "        for j in range(len(weights[0])): \n",
        "            # Initialize the node value depending on its corresponding parameters.\n",
        "            node = self.bias[j] # <- Insert code\n",
        "            # We now finish the linear transformation corresponding to the parameters of the currently considered node.\n",
        "            for i in range(len(single_input)):\n",
        "                node += weights[i][j] * single_input[i]  # <- Insert code\n",
        "            node = self.act_fn(node)\n",
        "            out.append(node)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpIZPBpNI0pO"
      },
      "source": [
        "## Exercise f) Add more activation functions\n",
        "\n",
        "To have a full definition of the neural network, we must define an activation function for every layer. Several activation functions have been proposed and have different characteristics. In the Var class we have already defined the rectified linear init (relu). \n",
        " \n",
        "Implement the following activation functions in the Var class:\n",
        "\n",
        "* Identity: $$\\mathrm{identity}(x) = x$$\n",
        "* Hyperbolic tangent: $$\\tanh(x)$$\n",
        "* Sigmoid (or logistic function): $$\\mathrm{sigmoid}(x) = \\frac{1}{1.0 + \\exp(-x ) }$$  Hint: $\\mathrm{sigmoid}'(x)= \\mathrm{sigmoid}(x)(1-\\mathrm{sigmoid}(x))$.  \n",
        "\n",
        "Hint: You can seek inspiration in the relu method in the Var class."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**solved in class - look at top of document**"
      ],
      "metadata": {
        "id": "dezTK4mF-OgE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_8n_SKnIW2F"
      },
      "source": [
        "## Exercise g) Complete the forward pass\n",
        "\n",
        "In the code below we initialize a 1-5-1 network and pass the training set through it. *The forward method in DenseLayer is **not** complete*. It just outputs zeros right now. The method forward should perform an [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) on the input followed by an application of the activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDEjtePxE7Mv",
        "outputId": "d12fdde4-562e-48fd-9428-536cc62b37b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[Var(v=0.0090, grad=0.0000)], [Var(v=0.0180, grad=0.0000)], [Var(v=0.0016, grad=0.0000)], [Var(v=-0.0122, grad=0.0000)], [Var(v=0.0133, grad=0.0000)], [Var(v=0.0123, grad=0.0000)], [Var(v=0.0080, grad=0.0000)], [Var(v=-0.0029, grad=0.0000)], [Var(v=-0.0126, grad=0.0000)], [Var(v=0.0049, grad=0.0000)], [Var(v=0.0139, grad=0.0000)], [Var(v=-0.0078, grad=0.0000)], [Var(v=0.0111, grad=0.0000)], [Var(v=-0.0089, grad=0.0000)], [Var(v=0.0059, grad=0.0000)], [Var(v=0.0116, grad=0.0000)], [Var(v=0.0213, grad=0.0000)], [Var(v=0.0101, grad=0.0000)], [Var(v=0.0011, grad=0.0000)], [Var(v=0.0035, grad=0.0000)], [Var(v=-0.0058, grad=0.0000)], [Var(v=-0.0026, grad=0.0000)], [Var(v=0.0156, grad=0.0000)], [Var(v=0.0157, grad=0.0000)], [Var(v=-0.0034, grad=0.0000)], [Var(v=-0.0092, grad=0.0000)], [Var(v=0.0202, grad=0.0000)], [Var(v=0.0222, grad=0.0000)], [Var(v=0.0024, grad=0.0000)], [Var(v=0.0140, grad=0.0000)], [Var(v=-0.0115, grad=0.0000)], [Var(v=0.0034, grad=0.0000)], [Var(v=-0.0100, grad=0.0000)], [Var(v=-0.0109, grad=0.0000)], [Var(v=0.0107, grad=0.0000)], [Var(v=-0.0020, grad=0.0000)], [Var(v=-0.0124, grad=0.0000)], [Var(v=-0.0047, grad=0.0000)], [Var(v=-0.0088, grad=0.0000)], [Var(v=-0.0063, grad=0.0000)], [Var(v=-0.0044, grad=0.0000)], [Var(v=-0.0060, grad=0.0000)], [Var(v=0.0209, grad=0.0000)], [Var(v=-0.0075, grad=0.0000)], [Var(v=-0.0059, grad=0.0000)], [Var(v=-0.0072, grad=0.0000)], [Var(v=0.0134, grad=0.0000)], [Var(v=0.0127, grad=0.0000)], [Var(v=-0.0028, grad=0.0000)], [Var(v=0.0130, grad=0.0000)], [Var(v=0.0057, grad=0.0000)], [Var(v=0.0005, grad=0.0000)], [Var(v=0.0141, grad=0.0000)], [Var(v=-0.0061, grad=0.0000)], [Var(v=0.0225, grad=0.0000)], [Var(v=0.0197, grad=0.0000)], [Var(v=-0.0041, grad=0.0000)], [Var(v=-0.0045, grad=0.0000)], [Var(v=0.0074, grad=0.0000)], [Var(v=-0.0108, grad=0.0000)], [Var(v=0.0131, grad=0.0000)], [Var(v=-0.0076, grad=0.0000)], [Var(v=-0.0125, grad=0.0000)], [Var(v=0.0064, grad=0.0000)], [Var(v=0.0047, grad=0.0000)], [Var(v=-0.0103, grad=0.0000)], [Var(v=-0.0110, grad=0.0000)], [Var(v=0.0166, grad=0.0000)], [Var(v=-0.0079, grad=0.0000)], [Var(v=0.0065, grad=0.0000)], [Var(v=-0.0030, grad=0.0000)], [Var(v=-0.0014, grad=0.0000)], [Var(v=0.0128, grad=0.0000)], [Var(v=0.0075, grad=0.0000)], [Var(v=-0.0011, grad=0.0000)], [Var(v=0.0203, grad=0.0000)], [Var(v=-0.0055, grad=0.0000)], [Var(v=-0.0053, grad=0.0000)], [Var(v=-0.0069, grad=0.0000)], [Var(v=0.0212, grad=0.0000)], [Var(v=0.0032, grad=0.0000)], [Var(v=0.0019, grad=0.0000)], [Var(v=-0.0113, grad=0.0000)], [Var(v=-0.0015, grad=0.0000)], [Var(v=-0.0057, grad=0.0000)], [Var(v=-0.0025, grad=0.0000)], [Var(v=-0.0021, grad=0.0000)], [Var(v=-0.0064, grad=0.0000)], [Var(v=-0.0117, grad=0.0000)], [Var(v=-0.0122, grad=0.0000)], [Var(v=0.0077, grad=0.0000)], [Var(v=-0.0037, grad=0.0000)], [Var(v=-0.0068, grad=0.0000)], [Var(v=0.0120, grad=0.0000)], [Var(v=-0.0096, grad=0.0000)], [Var(v=-0.0116, grad=0.0000)], [Var(v=0.0055, grad=0.0000)], [Var(v=0.0009, grad=0.0000)], [Var(v=0.0192, grad=0.0000)], [Var(v=-0.0069, grad=0.0000)], [Var(v=0.0126, grad=0.0000)], [Var(v=-0.0067, grad=0.0000)], [Var(v=-0.0102, grad=0.0000)], [Var(v=0.0061, grad=0.0000)], [Var(v=0.0179, grad=0.0000)]]\n"
          ]
        }
      ],
      "source": [
        "NN = [\n",
        "    DenseLayer(1, 5, lambda x: x.relu()),\n",
        "    DenseLayer(5, 1, lambda x: x.identity())\n",
        "]\n",
        "\n",
        "def forward(input, network):\n",
        "\n",
        "  def forward_single(x, network):\n",
        "    for layer in network:\n",
        "        x = layer.forward(x)\n",
        "    return x\n",
        "\n",
        "  output = [ forward_single(input[n], network) for n in range(len(input))]\n",
        "  return output\n",
        "\n",
        "print(forward(x_train, NN))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLrGJytZFtGm"
      },
      "source": [
        "## Exercise h) Print all network parameters\n",
        "\n",
        "Make a function that prints all the parameters of the network (weights and biases) with information about in which layer the appear. In the object oriented spirit you should introduce a method in the DenseLayer class to print the parameters of a layer. Hint: You can take inspiration from the corresponding method in Var. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iac-VwYGFtGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef063a78-6fd6-400c-f7ff-4a2444dc5b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: 0 Weights: [[Var(v=-0.0767, grad=0.0000), Var(v=0.0902, grad=0.0000), Var(v=-0.1025, grad=0.0000), Var(v=-0.0671, grad=0.0000), Var(v=0.0291, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000)]\n",
            "Layer: 1 Weights: [[Var(v=-0.1753, grad=0.0000)], [Var(v=0.1147, grad=0.0000)], [Var(v=-0.0471, grad=0.0000)], [Var(v=0.1524, grad=0.0000)], [Var(v=0.0717, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000)]\n"
          ]
        }
      ],
      "source": [
        "# Insert code here and in the DenseLayer class\n",
        "def layer_networks(NN=NN):\n",
        "  # printing information for each layer of the NN\n",
        "  for i in range(len(NN)):\n",
        "    string = 'Layer: ' + str(i) + ' ' + str(NN[i])\n",
        "    print(string)\n",
        "\n",
        "# by running this function all the parameters of the network and the belonging layer is printed\n",
        "layer_networks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_79HOAXrFtHK"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "Now that we have defined our activation functions we can visualize them to see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1FcylHqLTl-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e15b7cc2-3ead-4a84-c6be-dbd1c8ba63b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd456b4d090>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = np.linspace(-6, 6, 100)\n",
        "\n",
        "# convert from Var to ndarray  \n",
        "def Var_to_nparray(x):\n",
        "  y = np.zeros((len(x),len(x[0])))\n",
        "  for i in range(len(x)):\n",
        "    for j in range(len(x[0])):\n",
        "      y[i,j] = x[i][j].v\n",
        "  return y\n",
        "\n",
        "# define 1-1 network with weight = 1 and relu activation \n",
        "NN = [ DenseLayer(1, 1, lambda x: x.relu(), initializer = ConstantInitializer(1.0)) ] \n",
        "y = Var_to_nparray(forward(nparray_to_Var(x), NN))\n",
        "\n",
        "#y = Var_to_nparray(relu(nparray_to_Var(x)))\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oOL2UolJFtHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "dc0bae27-c2f3-41c3-9c4b-c138b576d82c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Testing all activation layers\n",
        "\n",
        "x = np.linspace(-6, 6, 100)\n",
        "units = {\n",
        "    \"identity\": lambda x: x.identity(),\n",
        "    \"sigmoid\": lambda x: x.sigmoid(),\n",
        "    \"relu\": lambda x: x.relu(),\n",
        "    \"tanh\": lambda x: x.tanh()\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "[plt.plot(x, Var_to_nparray(forward(nparray_to_Var(x), [DenseLayer(1, 1, unit, initializer = ConstantInitializer(1.0))]) ), label=unit_name, lw=2) for unit_name, unit in units.items()] # unit(nparray_to_Var(x))), label=unit_name, lw=2) for unit_name, unit in units.items()]\n",
        "plt.legend(loc=2, fontsize=16)\n",
        "plt.title('Our activation functions', fontsize=20)\n",
        "plt.ylim([-2, 5])\n",
        "plt.xlim([-6, 6])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-jdEl-7FtGs"
      },
      "source": [
        "# Advanced initialization schemes\n",
        "\n",
        "If we are not careful with initialization, the signals we propagate forward ($a^{(l)}$, $l=1,\\ldots,L$) and backward ($\\delta^l$, $l=L,L-1,\\ldots,1$) can blow up or shrink to zero. A statistical analysis of the variance of the signals for different activation functions can be found in these two papers: [Glorot initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) and [He initialization](https://arxiv.org/pdf/1502.01852v1.pdf). \n",
        "\n",
        "The result of the analyses are proposals for how to make the initialization such that the variance of the signals (forward and backward) are kept approxmimatly constant when propagating from layer to layer. The exact expressions depend upon the non-linear activation function used. In Glorot initialization, the aim is to keep both the forward and backward variances constant whereas He only aims at keeping the variance in the forward pass constant.\n",
        "\n",
        "We define $n_{in}$ and $n_{out}$ as the number of input units and output units of a particular layer. \n",
        "\n",
        "The Glorot initialization has the form: \n",
        "\n",
        "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{2 \\alpha }{n_{in} + n_{out}} \\bigg) \\ . $$\n",
        "\n",
        "where $N(\\mu,\\sigma^2)$ is a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$ and $\\alpha$ is a parameter that depends upon the activation function used. For $\\tanh$, $\\alpha=1$ and for Rectified Linear Unit (ReLU) activations, $\\alpha=2$. (It is also possible to use a uniform distribution for initialization, see [this blog post](https://mmuratarat.github.io/2019-02-25/xavier-glorot-he-weight-init).) \n",
        "\n",
        "The He initialization is very similar\n",
        "\n",
        "$$w_{ij} \\sim N \\bigg( 0, \\, \\frac{\\alpha}{n_{in}} \\bigg) \\ . $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqeyab9qFtGs"
      },
      "source": [
        "## Exercise i) Glorot and He initialization\n",
        " \n",
        "Using the Initializer class, implement functions that implement Glorot and He \n",
        "\n",
        "Explain briefly how you would test numerically that these initializations have the sought after property. Hint: See plots in Glorot paper.\n",
        "\n",
        "Comment: If you want to be more advanced then try to make a universal initializer taking both the activation function and type (Glorot or He) as argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Qyk01CgaFtGt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "## Glorot\n",
        "def DenseLayer_Glorot_tanh(n_in: int, n_out: int):\n",
        "  std = math.sqrt(2*1/(n_in+n_out)) # <- replace with proper initialization\n",
        "  return DenseLayer(n_in, n_out, lambda x: x.tanh(), initializer = NormalInitializer(std))\n",
        "\n",
        "## He\n",
        "def DenseLayer_He_relu(n_in: int, n_out: int):\n",
        "  std = math.sqrt(0, 2/n_in) # <- replace with proper initialization\n",
        "  return DenseLayer(n_in, n_out, lambda x: x.relu(), initializer = NormalInitializer(std))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I would show the distribution of the gradients by using the initializer."
      ],
      "metadata": {
        "id": "n9C6sJ2jSFGb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XyXBD37FtHk"
      },
      "source": [
        "## Exercise j) Forward pass unit test\n",
        "\n",
        "Write a bit of code to make a unit test that the forward pass works. This can be done by defining a simple network with for example all weights equal to one (using the ConstantInitializer method) and identity activation functions. \n",
        "\n",
        "Hints: Use the [assert](https://www.w3schools.com/python/ref_keyword_assert.asp), the nparray_to_Var and the Var_to_nparray commands. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k0miqRUAFtHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ea18bcef-46db-4a66-97cb-657f978e7d50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Insert code here\n",
        "# a simple network of 1-1 with weight = 1 and the identity activation\n",
        "NN = [DenseLayer(1, 1, lambda x: x.identity(), initializer = ConstantInitializer(1.0)) ]\n",
        "y = Var_to_nparray(forward(nparray_to_Var(x), NN))\n",
        "\n",
        "assert x.all() == y.all()\n",
        "\n",
        "plt.plot(y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCxhfFnFtHp"
      },
      "source": [
        "# Loss functions\n",
        "\n",
        "We are only missing a loss function to we need to define a loss function and its derivative with respect to the output of the neural network $y$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I2eDYKvAFtHq"
      },
      "outputs": [],
      "source": [
        "def squared_loss(t, y):\n",
        "  \n",
        "  # add check that sizes agree\n",
        "  \n",
        "  def squared_loss_single(t, y):\n",
        "    Loss = Var(0.0)\n",
        "    for i in range(len(t)): # sum over outputs\n",
        "      Loss += (t[i]-y[i]) ** 2\n",
        "    return Loss\n",
        "\n",
        "  Loss = Var(0.0)\n",
        "  for n in range(len(t)): # sum over training data\n",
        "    Loss += squared_loss_single(t[n],y[n])\n",
        "  return Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrwSJ2UWFtHu"
      },
      "source": [
        "## Exercise k) Implement cross entropy loss\n",
        "\n",
        "Insert code below to implement cross-entropy loss for general dimensionality of $t$. Use a logits formulation:\n",
        "$$\n",
        "\\rm{Loss} = - \\sum_i t_i \\, log \\, p_i \n",
        "$$\n",
        "with $p$ given by the the softmax function in terms of the logits $h$:\n",
        "$$\n",
        "p_i = \\frac{\\exp(h_i)}{\\sum_{i'} \\exp(h_{i'})} .\n",
        "$$\n",
        "Inserting $p$ in the expression for the loss gives\n",
        "$$\n",
        "\\rm{Loss} = - \\sum_i t_i h_i + \\rm{LogSumExp}(h) \\ ,\n",
        "$$\n",
        "where \n",
        "$$\n",
        "\\rm{LogSumExp}(h) = \\log \\sum_i \\exp h_i \\ .\n",
        "$$\n",
        "This is true for $t$ being a one-hot vector. \n",
        "\n",
        "Call the function to convince yourself it works. \n",
        "\n",
        "In practice you want to implement a [numerically stable](https://leimao.github.io/blog/LogSumExp/) version of LogSumExp. But we will not bother about that here.\n",
        "\n",
        "Help: You can add these methods in the Var class:\n",
        "\n",
        "    def exp(self):\n",
        "        return Var(exp(self.v), lambda: [(self, exp(self.v))])\n",
        "    \n",
        "    def log(self):\n",
        "        return Var(log(self.v), lambda: [(self, self.v ** -1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6nMuxyfzFtHv"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss(t, h):\n",
        "     \n",
        "    Loss = Var(0.0)\n",
        "    \n",
        "    # Insert code here\n",
        "    for i in range(1, len(t)-1):\n",
        "      Loss -= t[i][0].v * h[i][0].v  +  log(exp(h[i][0].v)) \n",
        "\n",
        "    return Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fAF5ew4FtHy"
      },
      "source": [
        "# Backward pass\n",
        "\n",
        "Now the magic happens! We get the calculation of the gradients for free. Just do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "iHyfPPI9Qqwu"
      },
      "outputs": [],
      "source": [
        "NN = [\n",
        "    DenseLayer(1, 5, lambda x: x.relu()),\n",
        "    DenseLayer(5, 1, lambda x: x.identity())\n",
        "]\n",
        "\n",
        "output = forward(x_train, NN)\n",
        "\n",
        "Loss = squared_loss(y_train,output)\n",
        "Loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49biIAYKQ1oG"
      },
      "source": [
        "and the gradients will be calculated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_rGt1bq_Q7uk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c2a316-d474-425b-d361-9aa5a0895639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 \n",
            " Weights: [[Var(v=0.0255, grad=-1.2093), Var(v=0.0701, grad=-0.4506), Var(v=0.0301, grad=-4.4112), Var(v=-0.1191, grad=-5.9812), Var(v=0.0755, grad=-11.1058)]] Biases: [Var(v=0.0000, grad=-1.0390), Var(v=0.0000, grad=-0.3872), Var(v=0.0000, grad=-3.7900), Var(v=0.0000, grad=5.4373), Var(v=0.0000, grad=-9.5418)]\n",
            "Layer 1 \n",
            " Weights: [[Var(v=0.0120, grad=-2.5580)], [Var(v=0.0045, grad=-7.0463)], [Var(v=0.0439, grad=-3.0270)], [Var(v=0.0618, grad=11.5246)], [Var(v=0.1105, grad=-7.5809)]] Biases: [Var(v=0.0000, grad=1.6346)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7d7qK0uFtH9"
      },
      "source": [
        "# Backward pass unit test\n",
        "\n",
        "Above we used finite differences to test that Nanograd is actually doing what it is supposed to do. We can in principle try the same for the neural network. But we will trust that the test above is enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBi8GOSFtIN"
      },
      "source": [
        "# Training and validation\n",
        "\n",
        "We are ready to train some neural networks!\n",
        "\n",
        "We initialize again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "01ePmzBzRtdh"
      },
      "outputs": [],
      "source": [
        "NN = [\n",
        "    DenseLayer(1, 15, lambda x: x.relu()),\n",
        "    DenseLayer(15, 50, lambda x: x.relu()),\n",
        "    DenseLayer(50, 1, lambda x: x.identity())\n",
        "]\n",
        "\n",
        "output = forward(x_train, NN)\n",
        "\n",
        "Loss = squared_loss(y_train,output)\n",
        "Loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10iRPiQ1ISHw"
      },
      "source": [
        "and make an update:\n",
        "\n",
        "We introduce a help function parameters to have a handle in all parameters in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dhAI7eyeznia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742336c7-9118-404a-8f5c-8a9ac985c813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network before update:\n",
            "Layer 0 \n",
            " Weights: [[Var(v=0.0402, grad=14.4463), Var(v=0.0544, grad=-3.9996), Var(v=0.0637, grad=7.5030), Var(v=0.0185, grad=8.8525), Var(v=0.0061, grad=-4.7813), Var(v=-0.1280, grad=-0.6714), Var(v=-0.0455, grad=0.0315), Var(v=-0.0681, grad=1.0742), Var(v=0.0058, grad=-3.7814), Var(v=0.0282, grad=-12.3724), Var(v=0.1017, grad=-0.0584), Var(v=-0.1352, grad=0.5289), Var(v=-0.0876, grad=2.0483), Var(v=0.1149, grad=-6.5185), Var(v=0.0866, grad=-4.8219)]] Biases: [Var(v=0.0000, grad=12.4107), Var(v=0.0000, grad=-3.4361), Var(v=0.0000, grad=6.4458), Var(v=0.0000, grad=7.6051), Var(v=0.0000, grad=-4.1076), Var(v=0.0000, grad=0.6103), Var(v=0.0000, grad=-0.0287), Var(v=0.0000, grad=-0.9763), Var(v=0.0000, grad=-3.2486), Var(v=0.0000, grad=-10.6291), Var(v=0.0000, grad=-0.0502), Var(v=0.0000, grad=-0.4807), Var(v=0.0000, grad=-1.8617), Var(v=0.0000, grad=-5.6000), Var(v=0.0000, grad=-4.1424)]\n",
            "Layer 1 \n",
            " Weights: [[Var(v=0.0406, grad=0.0000), Var(v=-0.1137, grad=0.0000), Var(v=-0.1249, grad=0.0000), Var(v=0.1113, grad=-0.2134), Var(v=0.1438, grad=0.3101), Var(v=0.0416, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.2229, grad=0.4921), Var(v=-0.0314, grad=0.2502), Var(v=-0.0584, grad=0.0000), Var(v=0.2602, grad=-0.1440), Var(v=0.0707, grad=0.0000), Var(v=-0.0145, grad=-0.7528), Var(v=0.1228, grad=-0.1483), Var(v=-0.0397, grad=0.0000), Var(v=0.0214, grad=0.1968), Var(v=-0.2356, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0753, grad=-0.7531), Var(v=0.0310, grad=-0.0594), Var(v=-0.0830, grad=0.0000), Var(v=0.0094, grad=-0.1184), Var(v=-0.0143, grad=0.0000), Var(v=-0.0554, grad=-0.2568), Var(v=0.0258, grad=0.1528), Var(v=-0.0924, grad=0.0000), Var(v=0.2400, grad=0.1726), Var(v=-0.0349, grad=0.0000), Var(v=-0.0691, grad=-0.1223), Var(v=-0.0983, grad=0.0000), Var(v=-0.0390, grad=0.1329), Var(v=0.0260, grad=0.0000), Var(v=0.1765, grad=0.2088), Var(v=-0.0335, grad=0.0000), Var(v=0.0637, grad=0.0000), Var(v=-0.0865, grad=0.0000), Var(v=-0.3231, grad=-0.1676), Var(v=0.0045, grad=-0.2195), Var(v=0.0197, grad=-0.4076), Var(v=0.0880, grad=0.0000), Var(v=0.0498, grad=0.0000), Var(v=0.2298, grad=1.2884), Var(v=-0.0660, grad=0.3114), Var(v=-0.0456, grad=-0.2443), Var(v=-0.0264, grad=-0.2692), Var(v=-0.0621, grad=0.0000), Var(v=-0.0426, grad=-0.1764), Var(v=-0.0581, grad=-0.0360), Var(v=-0.0811, grad=0.0489), Var(v=-0.1089, grad=0.0000)], [Var(v=-0.0895, grad=0.0000), Var(v=-0.1364, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0312, grad=-0.2893), Var(v=0.0003, grad=0.4203), Var(v=-0.0628, grad=0.0000), Var(v=-0.0728, grad=0.0000), Var(v=0.0328, grad=0.6671), Var(v=0.0141, grad=0.3392), Var(v=-0.1718, grad=0.0000), Var(v=0.0906, grad=-0.1952), Var(v=-0.0286, grad=0.0000), Var(v=-0.0169, grad=-1.0205), Var(v=-0.1515, grad=-0.2011), Var(v=0.0271, grad=0.0000), Var(v=-0.0462, grad=0.2668), Var(v=-0.0973, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.0813, grad=-1.0210), Var(v=0.0541, grad=-0.0806), Var(v=0.0591, grad=0.0000), Var(v=0.0023, grad=-0.1604), Var(v=-0.1213, grad=0.0000), Var(v=0.0753, grad=-0.3481), Var(v=-0.0881, grad=0.2072), Var(v=-0.0025, grad=0.0000), Var(v=-0.0302, grad=0.2339), Var(v=-0.1256, grad=0.0000), Var(v=-0.0646, grad=-0.1658), Var(v=0.1402, grad=0.0000), Var(v=0.0799, grad=0.1801), Var(v=-0.0787, grad=0.0000), Var(v=0.0878, grad=0.2830), Var(v=-0.1027, grad=0.0000), Var(v=-0.1323, grad=0.0000), Var(v=-0.0693, grad=0.0000), Var(v=0.1161, grad=-0.2271), Var(v=0.1067, grad=-0.2976), Var(v=-0.1821, grad=-0.5525), Var(v=-0.0556, grad=0.0000), Var(v=-0.0954, grad=0.0000), Var(v=-0.1053, grad=1.7465), Var(v=0.0128, grad=0.4222), Var(v=0.0609, grad=-0.3312), Var(v=-0.0931, grad=-0.3650), Var(v=-0.0926, grad=0.0000), Var(v=0.1112, grad=-0.2392), Var(v=0.0971, grad=-0.0488), Var(v=-0.1557, grad=0.0664), Var(v=0.1221, grad=0.0000)], [Var(v=0.0500, grad=0.0000), Var(v=-0.0801, grad=0.0000), Var(v=0.0031, grad=0.0000), Var(v=-0.0518, grad=-0.3386), Var(v=0.1418, grad=0.4920), Var(v=0.1393, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0463, grad=0.7808), Var(v=0.0252, grad=0.3970), Var(v=-0.1093, grad=0.0000), Var(v=-0.0184, grad=-0.2285), Var(v=-0.0278, grad=0.0000), Var(v=-0.0715, grad=-1.1945), Var(v=0.1750, grad=-0.2354), Var(v=-0.0183, grad=0.0000), Var(v=0.0268, grad=0.3123), Var(v=-0.0190, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=-0.0274, grad=-1.1951), Var(v=0.0649, grad=-0.0943), Var(v=-0.0883, grad=0.0000), Var(v=-0.0647, grad=-0.1878), Var(v=0.1525, grad=0.0000), Var(v=0.0660, grad=-0.4074), Var(v=-0.0960, grad=0.2425), Var(v=-0.1773, grad=0.0000), Var(v=0.0702, grad=0.2738), Var(v=-0.0378, grad=0.0000), Var(v=0.0216, grad=-0.1940), Var(v=0.2615, grad=0.0000), Var(v=0.1700, grad=0.2108), Var(v=-0.2148, grad=0.0000), Var(v=-0.0518, grad=0.3313), Var(v=-0.1286, grad=0.0000), Var(v=-0.1408, grad=0.0000), Var(v=-0.0273, grad=0.0000), Var(v=0.1168, grad=-0.2659), Var(v=0.0340, grad=-0.3484), Var(v=0.0805, grad=-0.6467), Var(v=-0.0840, grad=0.0000), Var(v=-0.1704, grad=0.0000), Var(v=0.1882, grad=2.0443), Var(v=-0.0016, grad=0.4941), Var(v=-0.0945, grad=-0.3876), Var(v=0.2218, grad=-0.4272), Var(v=-0.0022, grad=0.0000), Var(v=-0.0970, grad=-0.2799), Var(v=-0.1211, grad=-0.0571), Var(v=0.0109, grad=0.0777), Var(v=-0.1595, grad=0.0000)], [Var(v=-0.2340, grad=0.0000), Var(v=0.0158, grad=0.0000), Var(v=-0.0082, grad=0.0000), Var(v=-0.0003, grad=-0.0983), Var(v=0.2695, grad=0.1428), Var(v=0.0200, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0339, grad=0.2267), Var(v=0.0073, grad=0.1153), Var(v=-0.1148, grad=0.0000), Var(v=-0.1451, grad=-0.0663), Var(v=-0.0793, grad=0.0000), Var(v=-0.0217, grad=-0.3468), Var(v=0.0859, grad=-0.0683), Var(v=0.1416, grad=0.0000), Var(v=0.0572, grad=0.0907), Var(v=-0.0729, grad=0.0000), Var(v=0.0762, grad=0.0000), Var(v=-0.1319, grad=-0.3470), Var(v=0.1273, grad=-0.0274), Var(v=0.0247, grad=0.0000), Var(v=0.1630, grad=-0.0545), Var(v=0.0043, grad=0.0000), Var(v=-0.0383, grad=-0.1183), Var(v=0.1006, grad=0.0704), Var(v=0.1110, grad=0.0000), Var(v=-0.1468, grad=0.0795), Var(v=-0.0933, grad=0.0000), Var(v=-0.0159, grad=-0.0563), Var(v=-0.0103, grad=0.0000), Var(v=0.0162, grad=0.0612), Var(v=0.1673, grad=0.0000), Var(v=-0.0399, grad=0.0962), Var(v=0.0813, grad=0.0000), Var(v=-0.0832, grad=0.0000), Var(v=0.0587, grad=0.0000), Var(v=0.0907, grad=-0.0772), Var(v=-0.0668, grad=-0.1011), Var(v=-0.1190, grad=-0.1878), Var(v=-0.1015, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=-0.0043, grad=0.5935), Var(v=0.0865, grad=0.1435), Var(v=-0.0157, grad=-0.1125), Var(v=-0.2177, grad=-0.1240), Var(v=-0.1781, grad=0.0000), Var(v=-0.0684, grad=-0.0813), Var(v=0.0619, grad=-0.0166), Var(v=0.1599, grad=0.0225), Var(v=-0.0018, grad=0.0000)], [Var(v=0.0475, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.0389, grad=0.0000), Var(v=0.0341, grad=-0.0323), Var(v=-0.0343, grad=0.0470), Var(v=0.1777, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=-0.0884, grad=0.0745), Var(v=0.1205, grad=0.0379), Var(v=-0.0696, grad=0.0000), Var(v=0.1436, grad=-0.0218), Var(v=-0.0091, grad=0.0000), Var(v=-0.0428, grad=-0.1140), Var(v=-0.0787, grad=-0.0225), Var(v=-0.1918, grad=0.0000), Var(v=0.0572, grad=0.0298), Var(v=0.0986, grad=0.0000), Var(v=0.0572, grad=0.0000), Var(v=0.1142, grad=-0.1140), Var(v=-0.1692, grad=-0.0090), Var(v=-0.0829, grad=0.0000), Var(v=-0.0344, grad=-0.0179), Var(v=0.1496, grad=0.0000), Var(v=-0.0645, grad=-0.0389), Var(v=0.1521, grad=0.0231), Var(v=-0.1923, grad=0.0000), Var(v=0.1108, grad=0.0261), Var(v=0.0148, grad=0.0000), Var(v=0.2281, grad=-0.0185), Var(v=-0.0239, grad=0.0000), Var(v=0.1318, grad=0.0201), Var(v=-0.0023, grad=0.0000), Var(v=0.0060, grad=0.0316), Var(v=0.0401, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0727, grad=-0.0254), Var(v=0.0758, grad=-0.0332), Var(v=0.1202, grad=-0.0617), Var(v=-0.0196, grad=0.0000), Var(v=0.0091, grad=0.0000), Var(v=-0.1100, grad=0.1951), Var(v=0.1210, grad=0.0472), Var(v=0.0716, grad=-0.0370), Var(v=0.0032, grad=-0.0408), Var(v=0.0244, grad=0.0000), Var(v=-0.0202, grad=-0.0267), Var(v=0.0104, grad=-0.0055), Var(v=-0.0086, grad=0.0074), Var(v=0.0291, grad=0.0000)], [Var(v=0.0190, grad=0.0000), Var(v=-0.0149, grad=0.0000), Var(v=-0.2697, grad=0.0000), Var(v=-0.0151, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0378, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=0.0767, grad=0.4353), Var(v=-0.0539, grad=-0.5887), Var(v=-0.1327, grad=0.0000), Var(v=-0.0814, grad=0.4484), Var(v=0.0364, grad=0.6836), Var(v=0.0094, grad=-0.5948), Var(v=-0.0581, grad=0.0000), Var(v=0.0501, grad=0.7955), Var(v=-0.1174, grad=0.0000), Var(v=-0.0758, grad=0.0000), Var(v=0.0354, grad=1.7579), Var(v=-0.0081, grad=0.3577), Var(v=-0.0579, grad=0.0000), Var(v=0.0445, grad=0.7761), Var(v=0.0802, grad=-0.4619), Var(v=0.0910, grad=1.0784), Var(v=-0.0578, grad=0.0000), Var(v=0.0673, grad=1.5482), Var(v=0.0205, grad=0.0000), Var(v=0.1327, grad=-1.5858), Var(v=-0.0468, grad=-0.4016), Var(v=-0.1502, grad=0.0000), Var(v=0.2443, grad=-0.6310), Var(v=0.0206, grad=0.2216), Var(v=-0.2234, grad=0.0000), Var(v=-0.0005, grad=-1.2039), Var(v=0.1386, grad=0.0000), Var(v=0.0182, grad=0.6636), Var(v=-0.1382, grad=0.0000), Var(v=-0.1641, grad=0.0000), Var(v=0.0055, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0061, grad=0.0000), Var(v=0.0241, grad=0.0000), Var(v=-0.1647, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=0.1025, grad=0.5332), Var(v=-0.0752, grad=0.0000), Var(v=-0.0410, grad=-0.1479), Var(v=0.0156, grad=0.4356)], [Var(v=0.1675, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0261, grad=0.0000), Var(v=0.0072, grad=0.0000), Var(v=0.0339, grad=0.0000), Var(v=0.0695, grad=0.0000), Var(v=-0.0655, grad=0.0000), Var(v=0.0682, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.0382, grad=0.1546), Var(v=-0.0617, grad=-0.2091), Var(v=0.0189, grad=0.0000), Var(v=0.1678, grad=0.1592), Var(v=0.1178, grad=0.2427), Var(v=0.0629, grad=-0.2112), Var(v=0.0117, grad=0.0000), Var(v=0.0593, grad=0.2825), Var(v=-0.1200, grad=0.0000), Var(v=-0.1723, grad=0.0000), Var(v=-0.1133, grad=0.6242), Var(v=0.1159, grad=0.1270), Var(v=-0.0338, grad=0.0000), Var(v=0.0354, grad=0.2756), Var(v=-0.0792, grad=-0.1640), Var(v=-0.1875, grad=0.3830), Var(v=0.0911, grad=0.0000), Var(v=0.0126, grad=0.5498), Var(v=0.0718, grad=0.0000), Var(v=-0.0294, grad=-0.5631), Var(v=0.0575, grad=-0.1426), Var(v=0.0018, grad=0.0000), Var(v=0.0685, grad=-0.2241), Var(v=-0.2075, grad=0.0787), Var(v=-0.0130, grad=0.0000), Var(v=0.0619, grad=-0.4275), Var(v=0.1460, grad=0.0000), Var(v=0.1166, grad=0.2356), Var(v=0.0429, grad=0.0000), Var(v=-0.1112, grad=0.0000), Var(v=0.1543, grad=0.0000), Var(v=-0.1496, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=0.2003, grad=0.0000), Var(v=0.0206, grad=0.0000), Var(v=0.0871, grad=0.0000), Var(v=0.1819, grad=0.1893), Var(v=-0.1267, grad=0.0000), Var(v=0.0470, grad=-0.0525), Var(v=0.0615, grad=0.1547)], [Var(v=-0.0738, grad=0.0000), Var(v=0.0766, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=0.0013, grad=0.0000), Var(v=-0.0891, grad=0.0000), Var(v=-0.1327, grad=0.0000), Var(v=-0.0973, grad=0.0000), Var(v=-0.1091, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.0884, grad=0.2314), Var(v=0.0655, grad=-0.3131), Var(v=0.0840, grad=0.0000), Var(v=0.2213, grad=0.2384), Var(v=0.0106, grad=0.3635), Var(v=0.0379, grad=-0.3163), Var(v=-0.1012, grad=0.0000), Var(v=0.1155, grad=0.4230), Var(v=0.0681, grad=0.0000), Var(v=-0.1316, grad=0.0000), Var(v=-0.0633, grad=0.9348), Var(v=0.1029, grad=0.1902), Var(v=0.0019, grad=0.0000), Var(v=-0.0417, grad=0.4127), Var(v=-0.0810, grad=-0.2456), Var(v=0.1050, grad=0.5734), Var(v=-0.0335, grad=0.0000), Var(v=0.0622, grad=0.8232), Var(v=-0.0008, grad=0.0000), Var(v=0.0680, grad=-0.8432), Var(v=0.1986, grad=-0.2135), Var(v=-0.0590, grad=0.0000), Var(v=0.0319, grad=-0.3356), Var(v=0.1034, grad=0.1178), Var(v=0.0805, grad=0.0000), Var(v=-0.0007, grad=-0.6402), Var(v=0.0134, grad=0.0000), Var(v=-0.2004, grad=0.3528), Var(v=-0.0287, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0508, grad=0.0000), Var(v=0.1460, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.3720, grad=0.0000), Var(v=-0.1184, grad=0.2835), Var(v=0.0052, grad=0.0000), Var(v=0.1009, grad=-0.0787), Var(v=0.0428, grad=0.2316)], [Var(v=-0.1843, grad=0.0000), Var(v=0.0530, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=-0.0693, grad=-0.0307), Var(v=0.2688, grad=0.0447), Var(v=-0.0283, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.1569, grad=0.0709), Var(v=0.0092, grad=0.0360), Var(v=0.0027, grad=0.0000), Var(v=-0.1531, grad=-0.0207), Var(v=0.0365, grad=0.0000), Var(v=0.1197, grad=-0.1085), Var(v=0.1474, grad=-0.0214), Var(v=-0.0538, grad=0.0000), Var(v=0.1003, grad=0.0284), Var(v=0.0713, grad=0.0000), Var(v=-0.0231, grad=0.0000), Var(v=0.0471, grad=-0.1085), Var(v=0.0253, grad=-0.0086), Var(v=0.0869, grad=0.0000), Var(v=0.1309, grad=-0.0171), Var(v=0.0041, grad=0.0000), Var(v=0.0033, grad=-0.0370), Var(v=0.0519, grad=0.0220), Var(v=-0.0445, grad=0.0000), Var(v=-0.0381, grad=0.0249), Var(v=0.0331, grad=0.0000), Var(v=0.1288, grad=-0.0176), Var(v=-0.0250, grad=0.0000), Var(v=-0.0469, grad=0.0191), Var(v=-0.1743, grad=0.0000), Var(v=-0.1954, grad=0.0301), Var(v=-0.0595, grad=0.0000), Var(v=-0.0840, grad=0.0000), Var(v=0.0899, grad=0.0000), Var(v=-0.0382, grad=-0.0241), Var(v=0.1460, grad=-0.0316), Var(v=-0.0778, grad=-0.0587), Var(v=-0.0492, grad=0.0000), Var(v=-0.0442, grad=0.0000), Var(v=0.0579, grad=0.1856), Var(v=0.0275, grad=0.0449), Var(v=0.0531, grad=-0.0352), Var(v=0.0656, grad=-0.0388), Var(v=-0.1151, grad=0.0000), Var(v=0.2601, grad=-0.0254), Var(v=0.0003, grad=-0.0052), Var(v=-0.0590, grad=0.0071), Var(v=0.1215, grad=0.0000)], [Var(v=-0.0182, grad=0.0000), Var(v=0.0093, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=0.0275, grad=-0.1496), Var(v=-0.1147, grad=0.2174), Var(v=-0.0805, grad=0.0000), Var(v=-0.0318, grad=0.0000), Var(v=-0.0587, grad=0.3451), Var(v=0.0276, grad=0.1754), Var(v=-0.0359, grad=0.0000), Var(v=0.0784, grad=-0.1010), Var(v=0.0140, grad=0.0000), Var(v=0.0320, grad=-0.5279), Var(v=-0.0147, grad=-0.1040), Var(v=-0.0213, grad=0.0000), Var(v=-0.1356, grad=0.1380), Var(v=0.0186, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.2924, grad=-0.5281), Var(v=0.0445, grad=-0.0417), Var(v=-0.0305, grad=0.0000), Var(v=0.0047, grad=-0.0830), Var(v=-0.0270, grad=0.0000), Var(v=0.2467, grad=-0.1801), Var(v=-0.0496, grad=0.1072), Var(v=-0.0518, grad=0.0000), Var(v=0.0797, grad=0.1210), Var(v=-0.1970, grad=0.0000), Var(v=-0.0600, grad=-0.0857), Var(v=0.1257, grad=0.0000), Var(v=0.1140, grad=0.0932), Var(v=0.1515, grad=0.0000), Var(v=0.0159, grad=0.1464), Var(v=-0.0539, grad=0.0000), Var(v=0.0356, grad=0.0000), Var(v=0.0355, grad=0.0000), Var(v=-0.0668, grad=-0.1175), Var(v=-0.0616, grad=-0.1539), Var(v=-0.0885, grad=-0.2858), Var(v=-0.1654, grad=0.0000), Var(v=0.0631, grad=0.0000), Var(v=-0.1289, grad=0.9034), Var(v=-0.0542, grad=0.2184), Var(v=0.0240, grad=-0.1713), Var(v=-0.0135, grad=-0.1888), Var(v=-0.0108, grad=0.0000), Var(v=-0.0230, grad=-0.1237), Var(v=-0.0126, grad=-0.0253), Var(v=0.0212, grad=0.0343), Var(v=0.2518, grad=0.0000)], [Var(v=-0.0665, grad=0.0000), Var(v=0.0719, grad=0.0000), Var(v=0.0306, grad=0.0000), Var(v=0.0764, grad=-0.5407), Var(v=-0.1117, grad=0.7855), Var(v=-0.0642, grad=0.0000), Var(v=0.0449, grad=0.0000), Var(v=0.0712, grad=1.2466), Var(v=0.1639, grad=0.6338), Var(v=0.1338, grad=0.0000), Var(v=0.0254, grad=-0.3648), Var(v=-0.2667, grad=0.0000), Var(v=-0.0728, grad=-1.9071), Var(v=-0.0402, grad=-0.3758), Var(v=-0.0360, grad=0.0000), Var(v=0.0355, grad=0.4986), Var(v=0.0451, grad=0.0000), Var(v=-0.1342, grad=0.0000), Var(v=0.0526, grad=-1.9081), Var(v=-0.0067, grad=-0.1506), Var(v=-0.0882, grad=0.0000), Var(v=-0.0174, grad=-0.2998), Var(v=-0.1023, grad=0.0000), Var(v=-0.1110, grad=-0.6505), Var(v=0.1300, grad=0.3872), Var(v=0.0066, grad=0.0000), Var(v=0.0509, grad=0.4372), Var(v=0.0076, grad=0.0000), Var(v=0.0124, grad=-0.3098), Var(v=-0.0349, grad=0.0000), Var(v=0.0689, grad=0.3366), Var(v=-0.1068, grad=0.0000), Var(v=-0.1726, grad=0.5289), Var(v=-0.0530, grad=0.0000), Var(v=0.1469, grad=0.0000), Var(v=-0.1518, grad=0.0000), Var(v=-0.0576, grad=-0.4245), Var(v=0.1285, grad=-0.5562), Var(v=0.1825, grad=-1.0326), Var(v=-0.0874, grad=0.0000), Var(v=-0.1262, grad=0.0000), Var(v=0.0626, grad=3.2640), Var(v=-0.0461, grad=0.7889), Var(v=0.0212, grad=-0.6189), Var(v=0.0809, grad=-0.6820), Var(v=0.0633, grad=0.0000), Var(v=0.1258, grad=-0.4469), Var(v=0.1035, grad=-0.0912), Var(v=-0.0736, grad=0.1240), Var(v=-0.1349, grad=0.0000)], [Var(v=-0.1103, grad=0.0000), Var(v=-0.1065, grad=0.0000), Var(v=-0.1260, grad=0.0000), Var(v=-0.1211, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=-0.0786, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=0.0700, grad=0.0000), Var(v=-0.0507, grad=0.0000), Var(v=-0.0521, grad=0.0000), Var(v=0.0664, grad=0.4598), Var(v=0.1255, grad=-0.6220), Var(v=0.0663, grad=0.0000), Var(v=-0.0440, grad=0.4737), Var(v=0.0713, grad=0.7222), Var(v=0.0508, grad=-0.6284), Var(v=-0.0294, grad=0.0000), Var(v=-0.0125, grad=0.8405), Var(v=0.0698, grad=0.0000), Var(v=-0.0282, grad=0.0000), Var(v=0.0635, grad=1.8572), Var(v=-0.0154, grad=0.3779), Var(v=-0.0304, grad=0.0000), Var(v=-0.0475, grad=0.8199), Var(v=0.0125, grad=-0.4880), Var(v=0.0774, grad=1.1393), Var(v=0.1075, grad=0.0000), Var(v=-0.0588, grad=1.6356), Var(v=0.0377, grad=0.0000), Var(v=-0.0347, grad=-1.6754), Var(v=0.2213, grad=-0.4242), Var(v=-0.0508, grad=0.0000), Var(v=0.0850, grad=-0.6667), Var(v=0.0956, grad=0.2341), Var(v=0.0176, grad=0.0000), Var(v=0.0549, grad=-1.2719), Var(v=-0.2674, grad=0.0000), Var(v=0.0902, grad=0.7010), Var(v=-0.1129, grad=0.0000), Var(v=-0.1468, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0977, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0679, grad=0.0000), Var(v=-0.1683, grad=0.0000), Var(v=0.0332, grad=0.5633), Var(v=-0.0799, grad=0.0000), Var(v=0.0743, grad=-0.1563), Var(v=-0.0040, grad=0.4602)], [Var(v=0.0338, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.0513, grad=0.0000), Var(v=-0.1166, grad=0.0000), Var(v=0.0652, grad=0.0000), Var(v=-0.0888, grad=0.0000), Var(v=-0.0387, grad=0.0000), Var(v=-0.0911, grad=0.0000), Var(v=0.0544, grad=0.0000), Var(v=0.0807, grad=0.2978), Var(v=0.1010, grad=-0.4028), Var(v=-0.0912, grad=0.0000), Var(v=0.0576, grad=0.3068), Var(v=-0.0418, grad=0.4677), Var(v=-0.0119, grad=-0.4070), Var(v=-0.1435, grad=0.0000), Var(v=0.0368, grad=0.5443), Var(v=-0.0077, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=0.0008, grad=1.2027), Var(v=0.0222, grad=0.2447), Var(v=-0.1625, grad=0.0000), Var(v=0.0303, grad=0.5310), Var(v=-0.0110, grad=-0.3160), Var(v=-0.1851, grad=0.7378), Var(v=-0.1290, grad=0.0000), Var(v=-0.0041, grad=1.0592), Var(v=-0.1429, grad=0.0000), Var(v=0.0849, grad=-1.0850), Var(v=-0.3149, grad=-0.2747), Var(v=-0.0327, grad=0.0000), Var(v=-0.0839, grad=-0.4317), Var(v=0.0436, grad=0.1516), Var(v=0.0134, grad=0.0000), Var(v=0.1406, grad=-0.8237), Var(v=-0.0619, grad=0.0000), Var(v=-0.0570, grad=0.4540), Var(v=0.0580, grad=0.0000), Var(v=-0.1770, grad=0.0000), Var(v=-0.0492, grad=0.0000), Var(v=-0.2561, grad=0.0000), Var(v=-0.0652, grad=0.0000), Var(v=-0.1107, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0301, grad=0.0000), Var(v=0.0724, grad=0.3648), Var(v=0.1355, grad=0.0000), Var(v=-0.0697, grad=-0.1012), Var(v=0.0011, grad=0.2980)], [Var(v=-0.0215, grad=0.0000), Var(v=-0.1893, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.0200, grad=-0.6108), Var(v=0.1592, grad=0.8874), Var(v=-0.0036, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=0.1367, grad=1.4083), Var(v=0.0226, grad=0.7160), Var(v=-0.1851, grad=0.0000), Var(v=-0.0419, grad=-0.4121), Var(v=-0.1727, grad=0.0000), Var(v=0.2363, grad=-2.1544), Var(v=-0.1450, grad=-0.4246), Var(v=0.0540, grad=0.0000), Var(v=0.1847, grad=0.5632), Var(v=0.0251, grad=0.0000), Var(v=0.1406, grad=0.0000), Var(v=-0.0046, grad=-2.1555), Var(v=0.0770, grad=-0.1701), Var(v=-0.1107, grad=0.0000), Var(v=-0.0226, grad=-0.3387), Var(v=-0.1486, grad=0.0000), Var(v=0.0642, grad=-0.7349), Var(v=-0.0236, grad=0.4374), Var(v=-0.0261, grad=0.0000), Var(v=-0.0056, grad=0.4939), Var(v=0.0239, grad=0.0000), Var(v=0.1748, grad=-0.3499), Var(v=-0.1024, grad=0.0000), Var(v=0.0494, grad=0.3802), Var(v=0.0786, grad=0.0000), Var(v=0.2207, grad=0.5975), Var(v=0.1578, grad=0.0000), Var(v=-0.0171, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.1255, grad=-0.4795), Var(v=0.0960, grad=-0.6283), Var(v=0.1110, grad=-1.1665), Var(v=0.0320, grad=0.0000), Var(v=-0.0628, grad=0.0000), Var(v=-0.0982, grad=3.6873), Var(v=-0.0199, grad=0.8913), Var(v=0.0989, grad=-0.6991), Var(v=0.2195, grad=-0.7705), Var(v=-0.0564, grad=0.0000), Var(v=-0.0443, grad=-0.5049), Var(v=0.1054, grad=-0.1031), Var(v=0.2707, grad=0.1401), Var(v=-0.0147, grad=0.0000)], [Var(v=-0.0014, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.0045, grad=0.0000), Var(v=-0.0398, grad=-0.4599), Var(v=0.0844, grad=0.6682), Var(v=-0.0524, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=-0.1756, grad=1.0604), Var(v=-0.0506, grad=0.5392), Var(v=-0.1376, grad=0.0000), Var(v=-0.1004, grad=-0.3103), Var(v=0.0002, grad=0.0000), Var(v=0.0274, grad=-1.6222), Var(v=0.1702, grad=-0.3197), Var(v=-0.0472, grad=0.0000), Var(v=-0.1279, grad=0.4241), Var(v=-0.0285, grad=0.0000), Var(v=-0.0394, grad=0.0000), Var(v=-0.0590, grad=-1.6231), Var(v=-0.2120, grad=-0.1281), Var(v=-0.0115, grad=0.0000), Var(v=0.1131, grad=-0.2551), Var(v=0.1044, grad=0.0000), Var(v=0.1330, grad=-0.5534), Var(v=0.0269, grad=0.3293), Var(v=-0.0251, grad=0.0000), Var(v=0.0805, grad=0.3719), Var(v=-0.0453, grad=0.0000), Var(v=0.0029, grad=-0.2635), Var(v=-0.1391, grad=0.0000), Var(v=-0.0847, grad=0.2863), Var(v=0.0908, grad=0.0000), Var(v=-0.0738, grad=0.4499), Var(v=-0.0853, grad=0.0000), Var(v=-0.1653, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=0.0887, grad=-0.3611), Var(v=-0.0131, grad=-0.4731), Var(v=0.0972, grad=-0.8784), Var(v=-0.0154, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=-0.0278, grad=2.7765), Var(v=0.1157, grad=0.6711), Var(v=0.0741, grad=-0.5264), Var(v=0.0053, grad=-0.5802), Var(v=-0.1514, grad=0.0000), Var(v=0.0427, grad=-0.3802), Var(v=0.0077, grad=-0.0776), Var(v=0.1145, grad=0.1055), Var(v=-0.1156, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-4.5651), Var(v=0.0000, grad=6.6326), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=10.5258), Var(v=0.0000, grad=5.3516), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0103), Var(v=0.0000, grad=-4.1803), Var(v=0.0000, grad=-16.1023), Var(v=0.0000, grad=0.0106), Var(v=0.0000, grad=4.8537), Var(v=0.0000, grad=-0.0140), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=5.6488), Var(v=0.0000, grad=-16.1104), Var(v=0.0000, grad=-1.2716), Var(v=0.0000, grad=12.4823), Var(v=0.0000, grad=0.0084), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0183), Var(v=0.0000, grad=-0.0109), Var(v=0.0000, grad=7.6576), Var(v=0.0000, grad=3.6915), Var(v=0.0000, grad=10.9930), Var(v=0.0000, grad=-2.6155), Var(v=0.0000, grad=-11.2603), Var(v=0.0000, grad=-0.0095), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-0.0149), Var(v=0.0000, grad=1.5735), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=-8.5486), Var(v=0.0000, grad=-3.5842), Var(v=0.0000, grad=0.0156), Var(v=0.0000, grad=-8.7186), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=27.5588), Var(v=0.0000, grad=6.6614), Var(v=0.0000, grad=-5.2254), Var(v=0.0000, grad=-5.7588), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0126), Var(v=0.0000, grad=-0.7704), Var(v=0.0000, grad=-0.0035), Var(v=0.0000, grad=3.0931)]\n",
            "Layer 2 \n",
            " Weights: [[Var(v=-0.0645, grad=0.0000)], [Var(v=0.1794, grad=0.0000)], [Var(v=-0.0090, grad=0.0000)], [Var(v=0.0526, grad=-0.5521)], [Var(v=-0.0765, grad=-3.2485)], [Var(v=-0.0765, grad=0.0000)], [Var(v=0.0857, grad=0.0000)], [Var(v=-0.1213, grad=-1.9156)], [Var(v=-0.0617, grad=-1.7878)], [Var(v=-0.1811, grad=0.0000)], [Var(v=0.0355, grad=1.7847)], [Var(v=-0.0480, grad=1.9710)], [Var(v=0.1856, grad=-1.7170)], [Var(v=0.0366, grad=0.7488)], [Var(v=0.0558, grad=1.6018)], [Var(v=-0.0485, grad=-0.0171)], [Var(v=-0.0981, grad=0.0000)], [Var(v=0.0649, grad=1.7714)], [Var(v=0.1857, grad=-0.6199)], [Var(v=0.0147, grad=-0.0874)], [Var(v=0.1434, grad=0.3575)], [Var(v=0.0292, grad=0.5079)], [Var(v=0.0726, grad=0.0000)], [Var(v=0.0633, grad=-1.9066)], [Var(v=-0.0377, grad=-0.2896)], [Var(v=0.0880, grad=0.4336)], [Var(v=-0.0426, grad=-2.4176)], [Var(v=0.1263, grad=0.4890)], [Var(v=0.0302, grad=-1.6999)], [Var(v=-0.1294, grad=2.2041)], [Var(v=-0.0328, grad=-1.1272)], [Var(v=-0.0251, grad=0.0000)], [Var(v=-0.0515, grad=3.0282)], [Var(v=0.0181, grad=1.6263)], [Var(v=-0.0930, grad=0.0000)], [Var(v=-0.0982, grad=2.1492)], [Var(v=0.0413, grad=-1.6325)], [Var(v=0.0541, grad=-2.8622)], [Var(v=0.1005, grad=-3.1634)], [Var(v=0.0220, grad=0.0000)], [Var(v=0.0071, grad=0.0000)], [Var(v=-0.3177, grad=-0.4151)], [Var(v=-0.0768, grad=-0.1971)], [Var(v=0.0602, grad=-1.6683)], [Var(v=0.0664, grad=-3.8280)], [Var(v=0.0635, grad=0.0000)], [Var(v=0.0435, grad=1.4016)], [Var(v=0.0089, grad=-1.9585)], [Var(v=-0.0121, grad=-1.8542)], [Var(v=0.0355, grad=0.6961)]] Biases: [Var(v=0.0000, grad=0.2889)]\n",
            "\n",
            "Network after update:\n",
            "Layer 0 \n",
            " Weights: [[Var(v=-0.1043, grad=14.4463), Var(v=0.0944, grad=-3.9996), Var(v=-0.0113, grad=7.5030), Var(v=-0.0700, grad=8.8525), Var(v=0.0539, grad=-4.7813), Var(v=-0.1213, grad=-0.6714), Var(v=-0.0458, grad=0.0315), Var(v=-0.0788, grad=1.0742), Var(v=0.0436, grad=-3.7814), Var(v=0.1519, grad=-12.3724), Var(v=0.1023, grad=-0.0584), Var(v=-0.1405, grad=0.5289), Var(v=-0.1081, grad=2.0483), Var(v=0.1801, grad=-6.5185), Var(v=0.1348, grad=-4.8219)]] Biases: [Var(v=-0.1241, grad=12.4107), Var(v=0.0344, grad=-3.4361), Var(v=-0.0645, grad=6.4458), Var(v=-0.0761, grad=7.6051), Var(v=0.0411, grad=-4.1076), Var(v=-0.0061, grad=0.6103), Var(v=0.0003, grad=-0.0287), Var(v=0.0098, grad=-0.9763), Var(v=0.0325, grad=-3.2486), Var(v=0.1063, grad=-10.6291), Var(v=0.0005, grad=-0.0502), Var(v=0.0048, grad=-0.4807), Var(v=0.0186, grad=-1.8617), Var(v=0.0560, grad=-5.6000), Var(v=0.0414, grad=-4.1424)]\n",
            "Layer 1 \n",
            " Weights: [[Var(v=0.0406, grad=0.0000), Var(v=-0.1137, grad=0.0000), Var(v=-0.1249, grad=0.0000), Var(v=0.1134, grad=-0.2134), Var(v=0.1407, grad=0.3101), Var(v=0.0416, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.2180, grad=0.4921), Var(v=-0.0339, grad=0.2502), Var(v=-0.0584, grad=0.0000), Var(v=0.2616, grad=-0.1440), Var(v=0.0707, grad=0.0000), Var(v=-0.0070, grad=-0.7528), Var(v=0.1242, grad=-0.1483), Var(v=-0.0397, grad=0.0000), Var(v=0.0194, grad=0.1968), Var(v=-0.2356, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0678, grad=-0.7531), Var(v=0.0315, grad=-0.0594), Var(v=-0.0830, grad=0.0000), Var(v=0.0106, grad=-0.1184), Var(v=-0.0143, grad=0.0000), Var(v=-0.0528, grad=-0.2568), Var(v=0.0243, grad=0.1528), Var(v=-0.0924, grad=0.0000), Var(v=0.2383, grad=0.1726), Var(v=-0.0349, grad=0.0000), Var(v=-0.0679, grad=-0.1223), Var(v=-0.0983, grad=0.0000), Var(v=-0.0403, grad=0.1329), Var(v=0.0260, grad=0.0000), Var(v=0.1745, grad=0.2088), Var(v=-0.0335, grad=0.0000), Var(v=0.0637, grad=0.0000), Var(v=-0.0865, grad=0.0000), Var(v=-0.3215, grad=-0.1676), Var(v=0.0067, grad=-0.2195), Var(v=0.0237, grad=-0.4076), Var(v=0.0880, grad=0.0000), Var(v=0.0498, grad=0.0000), Var(v=0.2170, grad=1.2884), Var(v=-0.0691, grad=0.3114), Var(v=-0.0432, grad=-0.2443), Var(v=-0.0237, grad=-0.2692), Var(v=-0.0621, grad=0.0000), Var(v=-0.0408, grad=-0.1764), Var(v=-0.0578, grad=-0.0360), Var(v=-0.0816, grad=0.0489), Var(v=-0.1089, grad=0.0000)], [Var(v=-0.0895, grad=0.0000), Var(v=-0.1364, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0341, grad=-0.2893), Var(v=-0.0039, grad=0.4203), Var(v=-0.0628, grad=0.0000), Var(v=-0.0728, grad=0.0000), Var(v=0.0262, grad=0.6671), Var(v=0.0107, grad=0.3392), Var(v=-0.1718, grad=0.0000), Var(v=0.0925, grad=-0.1952), Var(v=-0.0286, grad=0.0000), Var(v=-0.0067, grad=-1.0205), Var(v=-0.1494, grad=-0.2011), Var(v=0.0271, grad=0.0000), Var(v=-0.0489, grad=0.2668), Var(v=-0.0973, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.0915, grad=-1.0210), Var(v=0.0549, grad=-0.0806), Var(v=0.0591, grad=0.0000), Var(v=0.0039, grad=-0.1604), Var(v=-0.1213, grad=0.0000), Var(v=0.0787, grad=-0.3481), Var(v=-0.0902, grad=0.2072), Var(v=-0.0025, grad=0.0000), Var(v=-0.0326, grad=0.2339), Var(v=-0.1256, grad=0.0000), Var(v=-0.0629, grad=-0.1658), Var(v=0.1402, grad=0.0000), Var(v=0.0781, grad=0.1801), Var(v=-0.0787, grad=0.0000), Var(v=0.0850, grad=0.2830), Var(v=-0.1027, grad=0.0000), Var(v=-0.1323, grad=0.0000), Var(v=-0.0693, grad=0.0000), Var(v=0.1184, grad=-0.2271), Var(v=0.1096, grad=-0.2976), Var(v=-0.1766, grad=-0.5525), Var(v=-0.0556, grad=0.0000), Var(v=-0.0954, grad=0.0000), Var(v=-0.1228, grad=1.7465), Var(v=0.0085, grad=0.4222), Var(v=0.0642, grad=-0.3312), Var(v=-0.0895, grad=-0.3650), Var(v=-0.0926, grad=0.0000), Var(v=0.1136, grad=-0.2392), Var(v=0.0976, grad=-0.0488), Var(v=-0.1564, grad=0.0664), Var(v=0.1221, grad=0.0000)], [Var(v=0.0500, grad=0.0000), Var(v=-0.0801, grad=0.0000), Var(v=0.0031, grad=0.0000), Var(v=-0.0484, grad=-0.3386), Var(v=0.1369, grad=0.4920), Var(v=0.1393, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0384, grad=0.7808), Var(v=0.0212, grad=0.3970), Var(v=-0.1093, grad=0.0000), Var(v=-0.0161, grad=-0.2285), Var(v=-0.0278, grad=0.0000), Var(v=-0.0596, grad=-1.1945), Var(v=0.1773, grad=-0.2354), Var(v=-0.0183, grad=0.0000), Var(v=0.0237, grad=0.3123), Var(v=-0.0190, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=-0.0154, grad=-1.1951), Var(v=0.0658, grad=-0.0943), Var(v=-0.0883, grad=0.0000), Var(v=-0.0628, grad=-0.1878), Var(v=0.1525, grad=0.0000), Var(v=0.0701, grad=-0.4074), Var(v=-0.0984, grad=0.2425), Var(v=-0.1773, grad=0.0000), Var(v=0.0674, grad=0.2738), Var(v=-0.0378, grad=0.0000), Var(v=0.0235, grad=-0.1940), Var(v=0.2615, grad=0.0000), Var(v=0.1678, grad=0.2108), Var(v=-0.2148, grad=0.0000), Var(v=-0.0551, grad=0.3313), Var(v=-0.1286, grad=0.0000), Var(v=-0.1408, grad=0.0000), Var(v=-0.0273, grad=0.0000), Var(v=0.1195, grad=-0.2659), Var(v=0.0375, grad=-0.3484), Var(v=0.0870, grad=-0.6467), Var(v=-0.0840, grad=0.0000), Var(v=-0.1704, grad=0.0000), Var(v=0.1677, grad=2.0443), Var(v=-0.0065, grad=0.4941), Var(v=-0.0906, grad=-0.3876), Var(v=0.2261, grad=-0.4272), Var(v=-0.0022, grad=0.0000), Var(v=-0.0942, grad=-0.2799), Var(v=-0.1206, grad=-0.0571), Var(v=0.0101, grad=0.0777), Var(v=-0.1595, grad=0.0000)], [Var(v=-0.2340, grad=0.0000), Var(v=0.0158, grad=0.0000), Var(v=-0.0082, grad=0.0000), Var(v=0.0006, grad=-0.0983), Var(v=0.2681, grad=0.1428), Var(v=0.0200, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0317, grad=0.2267), Var(v=0.0061, grad=0.1153), Var(v=-0.1148, grad=0.0000), Var(v=-0.1445, grad=-0.0663), Var(v=-0.0793, grad=0.0000), Var(v=-0.0182, grad=-0.3468), Var(v=0.0866, grad=-0.0683), Var(v=0.1416, grad=0.0000), Var(v=0.0563, grad=0.0907), Var(v=-0.0729, grad=0.0000), Var(v=0.0762, grad=0.0000), Var(v=-0.1284, grad=-0.3470), Var(v=0.1276, grad=-0.0274), Var(v=0.0247, grad=0.0000), Var(v=0.1635, grad=-0.0545), Var(v=0.0043, grad=0.0000), Var(v=-0.0371, grad=-0.1183), Var(v=0.0999, grad=0.0704), Var(v=0.1110, grad=0.0000), Var(v=-0.1476, grad=0.0795), Var(v=-0.0933, grad=0.0000), Var(v=-0.0153, grad=-0.0563), Var(v=-0.0103, grad=0.0000), Var(v=0.0156, grad=0.0612), Var(v=0.1673, grad=0.0000), Var(v=-0.0409, grad=0.0962), Var(v=0.0813, grad=0.0000), Var(v=-0.0832, grad=0.0000), Var(v=0.0587, grad=0.0000), Var(v=0.0914, grad=-0.0772), Var(v=-0.0658, grad=-0.1011), Var(v=-0.1171, grad=-0.1878), Var(v=-0.1015, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=-0.0102, grad=0.5935), Var(v=0.0851, grad=0.1435), Var(v=-0.0146, grad=-0.1125), Var(v=-0.2165, grad=-0.1240), Var(v=-0.1781, grad=0.0000), Var(v=-0.0676, grad=-0.0813), Var(v=0.0621, grad=-0.0166), Var(v=0.1597, grad=0.0225), Var(v=-0.0018, grad=0.0000)], [Var(v=0.0475, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.0389, grad=0.0000), Var(v=0.0344, grad=-0.0323), Var(v=-0.0348, grad=0.0470), Var(v=0.1777, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=-0.0891, grad=0.0745), Var(v=0.1201, grad=0.0379), Var(v=-0.0696, grad=0.0000), Var(v=0.1439, grad=-0.0218), Var(v=-0.0091, grad=0.0000), Var(v=-0.0416, grad=-0.1140), Var(v=-0.0785, grad=-0.0225), Var(v=-0.1918, grad=0.0000), Var(v=0.0569, grad=0.0298), Var(v=0.0986, grad=0.0000), Var(v=0.0572, grad=0.0000), Var(v=0.1154, grad=-0.1140), Var(v=-0.1691, grad=-0.0090), Var(v=-0.0829, grad=0.0000), Var(v=-0.0342, grad=-0.0179), Var(v=0.1496, grad=0.0000), Var(v=-0.0642, grad=-0.0389), Var(v=0.1518, grad=0.0231), Var(v=-0.1923, grad=0.0000), Var(v=0.1106, grad=0.0261), Var(v=0.0148, grad=0.0000), Var(v=0.2283, grad=-0.0185), Var(v=-0.0239, grad=0.0000), Var(v=0.1316, grad=0.0201), Var(v=-0.0023, grad=0.0000), Var(v=0.0057, grad=0.0316), Var(v=0.0401, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0725, grad=-0.0254), Var(v=0.0762, grad=-0.0332), Var(v=0.1208, grad=-0.0617), Var(v=-0.0196, grad=0.0000), Var(v=0.0091, grad=0.0000), Var(v=-0.1120, grad=0.1951), Var(v=0.1205, grad=0.0472), Var(v=0.0720, grad=-0.0370), Var(v=0.0036, grad=-0.0408), Var(v=0.0244, grad=0.0000), Var(v=-0.0199, grad=-0.0267), Var(v=0.0104, grad=-0.0055), Var(v=-0.0087, grad=0.0074), Var(v=0.0291, grad=0.0000)], [Var(v=0.0190, grad=0.0000), Var(v=-0.0149, grad=0.0000), Var(v=-0.2697, grad=0.0000), Var(v=-0.0151, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0378, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=0.0724, grad=0.4353), Var(v=-0.0480, grad=-0.5887), Var(v=-0.1327, grad=0.0000), Var(v=-0.0858, grad=0.4484), Var(v=0.0296, grad=0.6836), Var(v=0.0154, grad=-0.5948), Var(v=-0.0581, grad=0.0000), Var(v=0.0421, grad=0.7955), Var(v=-0.1174, grad=0.0000), Var(v=-0.0758, grad=0.0000), Var(v=0.0178, grad=1.7579), Var(v=-0.0117, grad=0.3577), Var(v=-0.0579, grad=0.0000), Var(v=0.0367, grad=0.7761), Var(v=0.0849, grad=-0.4619), Var(v=0.0802, grad=1.0784), Var(v=-0.0578, grad=0.0000), Var(v=0.0518, grad=1.5482), Var(v=0.0205, grad=0.0000), Var(v=0.1485, grad=-1.5858), Var(v=-0.0428, grad=-0.4016), Var(v=-0.1502, grad=0.0000), Var(v=0.2506, grad=-0.6310), Var(v=0.0184, grad=0.2216), Var(v=-0.2234, grad=0.0000), Var(v=0.0115, grad=-1.2039), Var(v=0.1386, grad=0.0000), Var(v=0.0116, grad=0.6636), Var(v=-0.1382, grad=0.0000), Var(v=-0.1641, grad=0.0000), Var(v=0.0055, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0061, grad=0.0000), Var(v=0.0241, grad=0.0000), Var(v=-0.1647, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=0.0972, grad=0.5332), Var(v=-0.0752, grad=0.0000), Var(v=-0.0395, grad=-0.1479), Var(v=0.0113, grad=0.4356)], [Var(v=0.1675, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0261, grad=0.0000), Var(v=0.0072, grad=0.0000), Var(v=0.0339, grad=0.0000), Var(v=0.0695, grad=0.0000), Var(v=-0.0655, grad=0.0000), Var(v=0.0682, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.0366, grad=0.1546), Var(v=-0.0596, grad=-0.2091), Var(v=0.0189, grad=0.0000), Var(v=0.1662, grad=0.1592), Var(v=0.1154, grad=0.2427), Var(v=0.0650, grad=-0.2112), Var(v=0.0117, grad=0.0000), Var(v=0.0565, grad=0.2825), Var(v=-0.1200, grad=0.0000), Var(v=-0.1723, grad=0.0000), Var(v=-0.1196, grad=0.6242), Var(v=0.1146, grad=0.1270), Var(v=-0.0338, grad=0.0000), Var(v=0.0327, grad=0.2756), Var(v=-0.0776, grad=-0.1640), Var(v=-0.1913, grad=0.3830), Var(v=0.0911, grad=0.0000), Var(v=0.0071, grad=0.5498), Var(v=0.0718, grad=0.0000), Var(v=-0.0237, grad=-0.5631), Var(v=0.0589, grad=-0.1426), Var(v=0.0018, grad=0.0000), Var(v=0.0707, grad=-0.2241), Var(v=-0.2083, grad=0.0787), Var(v=-0.0130, grad=0.0000), Var(v=0.0662, grad=-0.4275), Var(v=0.1460, grad=0.0000), Var(v=0.1142, grad=0.2356), Var(v=0.0429, grad=0.0000), Var(v=-0.1112, grad=0.0000), Var(v=0.1543, grad=0.0000), Var(v=-0.1496, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=0.2003, grad=0.0000), Var(v=0.0206, grad=0.0000), Var(v=0.0871, grad=0.0000), Var(v=0.1800, grad=0.1893), Var(v=-0.1267, grad=0.0000), Var(v=0.0476, grad=-0.0525), Var(v=0.0600, grad=0.1547)], [Var(v=-0.0738, grad=0.0000), Var(v=0.0766, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=0.0013, grad=0.0000), Var(v=-0.0891, grad=0.0000), Var(v=-0.1327, grad=0.0000), Var(v=-0.0973, grad=0.0000), Var(v=-0.1091, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.0907, grad=0.2314), Var(v=0.0687, grad=-0.3131), Var(v=0.0840, grad=0.0000), Var(v=0.2189, grad=0.2384), Var(v=0.0070, grad=0.3635), Var(v=0.0410, grad=-0.3163), Var(v=-0.1012, grad=0.0000), Var(v=0.1113, grad=0.4230), Var(v=0.0681, grad=0.0000), Var(v=-0.1316, grad=0.0000), Var(v=-0.0726, grad=0.9348), Var(v=0.1010, grad=0.1902), Var(v=0.0019, grad=0.0000), Var(v=-0.0458, grad=0.4127), Var(v=-0.0785, grad=-0.2456), Var(v=0.0993, grad=0.5734), Var(v=-0.0335, grad=0.0000), Var(v=0.0540, grad=0.8232), Var(v=-0.0008, grad=0.0000), Var(v=0.0765, grad=-0.8432), Var(v=0.2007, grad=-0.2135), Var(v=-0.0590, grad=0.0000), Var(v=0.0353, grad=-0.3356), Var(v=0.1022, grad=0.1178), Var(v=0.0805, grad=0.0000), Var(v=0.0057, grad=-0.6402), Var(v=0.0134, grad=0.0000), Var(v=-0.2039, grad=0.3528), Var(v=-0.0287, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0508, grad=0.0000), Var(v=0.1460, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.3720, grad=0.0000), Var(v=-0.1212, grad=0.2835), Var(v=0.0052, grad=0.0000), Var(v=0.1017, grad=-0.0787), Var(v=0.0405, grad=0.2316)], [Var(v=-0.1843, grad=0.0000), Var(v=0.0530, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=-0.0690, grad=-0.0307), Var(v=0.2684, grad=0.0447), Var(v=-0.0283, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.1576, grad=0.0709), Var(v=0.0088, grad=0.0360), Var(v=0.0027, grad=0.0000), Var(v=-0.1529, grad=-0.0207), Var(v=0.0365, grad=0.0000), Var(v=0.1208, grad=-0.1085), Var(v=0.1476, grad=-0.0214), Var(v=-0.0538, grad=0.0000), Var(v=0.1000, grad=0.0284), Var(v=0.0713, grad=0.0000), Var(v=-0.0231, grad=0.0000), Var(v=0.0482, grad=-0.1085), Var(v=0.0253, grad=-0.0086), Var(v=0.0869, grad=0.0000), Var(v=0.1311, grad=-0.0171), Var(v=0.0041, grad=0.0000), Var(v=0.0037, grad=-0.0370), Var(v=0.0517, grad=0.0220), Var(v=-0.0445, grad=0.0000), Var(v=-0.0383, grad=0.0249), Var(v=0.0331, grad=0.0000), Var(v=0.1290, grad=-0.0176), Var(v=-0.0250, grad=0.0000), Var(v=-0.0471, grad=0.0191), Var(v=-0.1743, grad=0.0000), Var(v=-0.1957, grad=0.0301), Var(v=-0.0595, grad=0.0000), Var(v=-0.0840, grad=0.0000), Var(v=0.0899, grad=0.0000), Var(v=-0.0380, grad=-0.0241), Var(v=0.1464, grad=-0.0316), Var(v=-0.0773, grad=-0.0587), Var(v=-0.0492, grad=0.0000), Var(v=-0.0442, grad=0.0000), Var(v=0.0561, grad=0.1856), Var(v=0.0270, grad=0.0449), Var(v=0.0534, grad=-0.0352), Var(v=0.0660, grad=-0.0388), Var(v=-0.1151, grad=0.0000), Var(v=0.2603, grad=-0.0254), Var(v=0.0004, grad=-0.0052), Var(v=-0.0591, grad=0.0071), Var(v=0.1215, grad=0.0000)], [Var(v=-0.0182, grad=0.0000), Var(v=0.0093, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=0.0290, grad=-0.1496), Var(v=-0.1169, grad=0.2174), Var(v=-0.0805, grad=0.0000), Var(v=-0.0318, grad=0.0000), Var(v=-0.0621, grad=0.3451), Var(v=0.0259, grad=0.1754), Var(v=-0.0359, grad=0.0000), Var(v=0.0794, grad=-0.1010), Var(v=0.0140, grad=0.0000), Var(v=0.0372, grad=-0.5279), Var(v=-0.0137, grad=-0.1040), Var(v=-0.0213, grad=0.0000), Var(v=-0.1370, grad=0.1380), Var(v=0.0186, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.2977, grad=-0.5281), Var(v=0.0449, grad=-0.0417), Var(v=-0.0305, grad=0.0000), Var(v=0.0055, grad=-0.0830), Var(v=-0.0270, grad=0.0000), Var(v=0.2485, grad=-0.1801), Var(v=-0.0507, grad=0.1072), Var(v=-0.0518, grad=0.0000), Var(v=0.0785, grad=0.1210), Var(v=-0.1970, grad=0.0000), Var(v=-0.0591, grad=-0.0857), Var(v=0.1257, grad=0.0000), Var(v=0.1131, grad=0.0932), Var(v=0.1515, grad=0.0000), Var(v=0.0144, grad=0.1464), Var(v=-0.0539, grad=0.0000), Var(v=0.0356, grad=0.0000), Var(v=0.0355, grad=0.0000), Var(v=-0.0657, grad=-0.1175), Var(v=-0.0600, grad=-0.1539), Var(v=-0.0857, grad=-0.2858), Var(v=-0.1654, grad=0.0000), Var(v=0.0631, grad=0.0000), Var(v=-0.1380, grad=0.9034), Var(v=-0.0564, grad=0.2184), Var(v=0.0257, grad=-0.1713), Var(v=-0.0116, grad=-0.1888), Var(v=-0.0108, grad=0.0000), Var(v=-0.0218, grad=-0.1237), Var(v=-0.0124, grad=-0.0253), Var(v=0.0209, grad=0.0343), Var(v=0.2518, grad=0.0000)], [Var(v=-0.0665, grad=0.0000), Var(v=0.0719, grad=0.0000), Var(v=0.0306, grad=0.0000), Var(v=0.0818, grad=-0.5407), Var(v=-0.1195, grad=0.7855), Var(v=-0.0642, grad=0.0000), Var(v=0.0449, grad=0.0000), Var(v=0.0587, grad=1.2466), Var(v=0.1576, grad=0.6338), Var(v=0.1338, grad=0.0000), Var(v=0.0290, grad=-0.3648), Var(v=-0.2667, grad=0.0000), Var(v=-0.0537, grad=-1.9071), Var(v=-0.0364, grad=-0.3758), Var(v=-0.0360, grad=0.0000), Var(v=0.0305, grad=0.4986), Var(v=0.0451, grad=0.0000), Var(v=-0.1342, grad=0.0000), Var(v=0.0717, grad=-1.9081), Var(v=-0.0052, grad=-0.1506), Var(v=-0.0882, grad=0.0000), Var(v=-0.0144, grad=-0.2998), Var(v=-0.1023, grad=0.0000), Var(v=-0.1044, grad=-0.6505), Var(v=0.1261, grad=0.3872), Var(v=0.0066, grad=0.0000), Var(v=0.0465, grad=0.4372), Var(v=0.0076, grad=0.0000), Var(v=0.0155, grad=-0.3098), Var(v=-0.0349, grad=0.0000), Var(v=0.0656, grad=0.3366), Var(v=-0.1068, grad=0.0000), Var(v=-0.1779, grad=0.5289), Var(v=-0.0530, grad=0.0000), Var(v=0.1469, grad=0.0000), Var(v=-0.1518, grad=0.0000), Var(v=-0.0533, grad=-0.4245), Var(v=0.1341, grad=-0.5562), Var(v=0.1928, grad=-1.0326), Var(v=-0.0874, grad=0.0000), Var(v=-0.1262, grad=0.0000), Var(v=0.0299, grad=3.2640), Var(v=-0.0539, grad=0.7889), Var(v=0.0274, grad=-0.6189), Var(v=0.0877, grad=-0.6820), Var(v=0.0633, grad=0.0000), Var(v=0.1303, grad=-0.4469), Var(v=0.1044, grad=-0.0912), Var(v=-0.0748, grad=0.1240), Var(v=-0.1349, grad=0.0000)], [Var(v=-0.1103, grad=0.0000), Var(v=-0.1065, grad=0.0000), Var(v=-0.1260, grad=0.0000), Var(v=-0.1211, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=-0.0786, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=0.0700, grad=0.0000), Var(v=-0.0507, grad=0.0000), Var(v=-0.0521, grad=0.0000), Var(v=0.0618, grad=0.4598), Var(v=0.1317, grad=-0.6220), Var(v=0.0663, grad=0.0000), Var(v=-0.0487, grad=0.4737), Var(v=0.0641, grad=0.7222), Var(v=0.0571, grad=-0.6284), Var(v=-0.0294, grad=0.0000), Var(v=-0.0209, grad=0.8405), Var(v=0.0698, grad=0.0000), Var(v=-0.0282, grad=0.0000), Var(v=0.0450, grad=1.8572), Var(v=-0.0192, grad=0.3779), Var(v=-0.0304, grad=0.0000), Var(v=-0.0557, grad=0.8199), Var(v=0.0173, grad=-0.4880), Var(v=0.0660, grad=1.1393), Var(v=0.1075, grad=0.0000), Var(v=-0.0752, grad=1.6356), Var(v=0.0377, grad=0.0000), Var(v=-0.0180, grad=-1.6754), Var(v=0.2256, grad=-0.4242), Var(v=-0.0508, grad=0.0000), Var(v=0.0916, grad=-0.6667), Var(v=0.0932, grad=0.2341), Var(v=0.0176, grad=0.0000), Var(v=0.0677, grad=-1.2719), Var(v=-0.2674, grad=0.0000), Var(v=0.0832, grad=0.7010), Var(v=-0.1129, grad=0.0000), Var(v=-0.1468, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0977, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0679, grad=0.0000), Var(v=-0.1683, grad=0.0000), Var(v=0.0276, grad=0.5633), Var(v=-0.0799, grad=0.0000), Var(v=0.0758, grad=-0.1563), Var(v=-0.0086, grad=0.4602)], [Var(v=0.0338, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.0513, grad=0.0000), Var(v=-0.1166, grad=0.0000), Var(v=0.0652, grad=0.0000), Var(v=-0.0888, grad=0.0000), Var(v=-0.0387, grad=0.0000), Var(v=-0.0911, grad=0.0000), Var(v=0.0544, grad=0.0000), Var(v=0.0777, grad=0.2978), Var(v=0.1051, grad=-0.4028), Var(v=-0.0912, grad=0.0000), Var(v=0.0545, grad=0.3068), Var(v=-0.0465, grad=0.4677), Var(v=-0.0078, grad=-0.4070), Var(v=-0.1435, grad=0.0000), Var(v=0.0313, grad=0.5443), Var(v=-0.0077, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=-0.0112, grad=1.2027), Var(v=0.0197, grad=0.2447), Var(v=-0.1625, grad=0.0000), Var(v=0.0250, grad=0.5310), Var(v=-0.0079, grad=-0.3160), Var(v=-0.1925, grad=0.7378), Var(v=-0.1290, grad=0.0000), Var(v=-0.0147, grad=1.0592), Var(v=-0.1429, grad=0.0000), Var(v=0.0957, grad=-1.0850), Var(v=-0.3121, grad=-0.2747), Var(v=-0.0327, grad=0.0000), Var(v=-0.0796, grad=-0.4317), Var(v=0.0421, grad=0.1516), Var(v=0.0134, grad=0.0000), Var(v=0.1488, grad=-0.8237), Var(v=-0.0619, grad=0.0000), Var(v=-0.0616, grad=0.4540), Var(v=0.0580, grad=0.0000), Var(v=-0.1770, grad=0.0000), Var(v=-0.0492, grad=0.0000), Var(v=-0.2561, grad=0.0000), Var(v=-0.0652, grad=0.0000), Var(v=-0.1107, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0301, grad=0.0000), Var(v=0.0688, grad=0.3648), Var(v=0.1355, grad=0.0000), Var(v=-0.0687, grad=-0.1012), Var(v=-0.0019, grad=0.2980)], [Var(v=-0.0215, grad=0.0000), Var(v=-0.1893, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.0139, grad=-0.6108), Var(v=0.1503, grad=0.8874), Var(v=-0.0036, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=0.1226, grad=1.4083), Var(v=0.0154, grad=0.7160), Var(v=-0.1851, grad=0.0000), Var(v=-0.0378, grad=-0.4121), Var(v=-0.1727, grad=0.0000), Var(v=0.2579, grad=-2.1544), Var(v=-0.1408, grad=-0.4246), Var(v=0.0540, grad=0.0000), Var(v=0.1791, grad=0.5632), Var(v=0.0251, grad=0.0000), Var(v=0.1406, grad=0.0000), Var(v=0.0170, grad=-2.1555), Var(v=0.0787, grad=-0.1701), Var(v=-0.1107, grad=0.0000), Var(v=-0.0192, grad=-0.3387), Var(v=-0.1486, grad=0.0000), Var(v=0.0715, grad=-0.7349), Var(v=-0.0280, grad=0.4374), Var(v=-0.0261, grad=0.0000), Var(v=-0.0106, grad=0.4939), Var(v=0.0239, grad=0.0000), Var(v=0.1783, grad=-0.3499), Var(v=-0.1024, grad=0.0000), Var(v=0.0456, grad=0.3802), Var(v=0.0786, grad=0.0000), Var(v=0.2147, grad=0.5975), Var(v=0.1578, grad=0.0000), Var(v=-0.0171, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.1303, grad=-0.4795), Var(v=0.1023, grad=-0.6283), Var(v=0.1227, grad=-1.1665), Var(v=0.0320, grad=0.0000), Var(v=-0.0628, grad=0.0000), Var(v=-0.1351, grad=3.6873), Var(v=-0.0288, grad=0.8913), Var(v=0.1059, grad=-0.6991), Var(v=0.2272, grad=-0.7705), Var(v=-0.0564, grad=0.0000), Var(v=-0.0392, grad=-0.5049), Var(v=0.1064, grad=-0.1031), Var(v=0.2693, grad=0.1401), Var(v=-0.0147, grad=0.0000)], [Var(v=-0.0014, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.0045, grad=0.0000), Var(v=-0.0352, grad=-0.4599), Var(v=0.0777, grad=0.6682), Var(v=-0.0524, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=-0.1862, grad=1.0604), Var(v=-0.0560, grad=0.5392), Var(v=-0.1376, grad=0.0000), Var(v=-0.0973, grad=-0.3103), Var(v=0.0002, grad=0.0000), Var(v=0.0437, grad=-1.6222), Var(v=0.1734, grad=-0.3197), Var(v=-0.0472, grad=0.0000), Var(v=-0.1321, grad=0.4241), Var(v=-0.0285, grad=0.0000), Var(v=-0.0394, grad=0.0000), Var(v=-0.0428, grad=-1.6231), Var(v=-0.2107, grad=-0.1281), Var(v=-0.0115, grad=0.0000), Var(v=0.1156, grad=-0.2551), Var(v=0.1044, grad=0.0000), Var(v=0.1385, grad=-0.5534), Var(v=0.0236, grad=0.3293), Var(v=-0.0251, grad=0.0000), Var(v=0.0768, grad=0.3719), Var(v=-0.0453, grad=0.0000), Var(v=0.0055, grad=-0.2635), Var(v=-0.1391, grad=0.0000), Var(v=-0.0876, grad=0.2863), Var(v=0.0908, grad=0.0000), Var(v=-0.0783, grad=0.4499), Var(v=-0.0853, grad=0.0000), Var(v=-0.1653, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=0.0923, grad=-0.3611), Var(v=-0.0083, grad=-0.4731), Var(v=0.1060, grad=-0.8784), Var(v=-0.0154, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=-0.0556, grad=2.7765), Var(v=0.1090, grad=0.6711), Var(v=0.0793, grad=-0.5264), Var(v=0.0111, grad=-0.5802), Var(v=-0.1514, grad=0.0000), Var(v=0.0465, grad=-0.3802), Var(v=0.0085, grad=-0.0776), Var(v=0.1134, grad=0.1055), Var(v=-0.1156, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0457, grad=-4.5651), Var(v=-0.0663, grad=6.6326), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.1053, grad=10.5258), Var(v=-0.0535, grad=5.3516), Var(v=0.0000, grad=0.0000), Var(v=-0.0001, grad=0.0103), Var(v=0.0418, grad=-4.1803), Var(v=0.1610, grad=-16.1023), Var(v=-0.0001, grad=0.0106), Var(v=-0.0485, grad=4.8537), Var(v=0.0001, grad=-0.0140), Var(v=0.0000, grad=0.0000), Var(v=-0.0565, grad=5.6488), Var(v=0.1611, grad=-16.1104), Var(v=0.0127, grad=-1.2716), Var(v=-0.1248, grad=12.4823), Var(v=-0.0001, grad=0.0084), Var(v=0.0000, grad=0.0000), Var(v=-0.0002, grad=0.0183), Var(v=0.0001, grad=-0.0109), Var(v=-0.0766, grad=7.6576), Var(v=-0.0369, grad=3.6915), Var(v=-0.1099, grad=10.9930), Var(v=0.0262, grad=-2.6155), Var(v=0.1126, grad=-11.2603), Var(v=0.0001, grad=-0.0095), Var(v=0.0000, grad=0.0000), Var(v=0.0001, grad=-0.0149), Var(v=-0.0157, grad=1.5735), Var(v=0.0000, grad=0.0000), Var(v=0.0855, grad=-8.5486), Var(v=0.0358, grad=-3.5842), Var(v=-0.0002, grad=0.0156), Var(v=0.0872, grad=-8.7186), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.2756, grad=27.5588), Var(v=-0.0666, grad=6.6614), Var(v=0.0523, grad=-5.2254), Var(v=0.0576, grad=-5.7588), Var(v=0.0000, grad=0.0000), Var(v=-0.0001, grad=0.0126), Var(v=0.0077, grad=-0.7704), Var(v=0.0000, grad=-0.0035), Var(v=-0.0309, grad=3.0931)]\n",
            "Layer 2 \n",
            " Weights: [[Var(v=-0.0645, grad=0.0000)], [Var(v=0.1794, grad=0.0000)], [Var(v=-0.0090, grad=0.0000)], [Var(v=0.0581, grad=-0.5521)], [Var(v=-0.0440, grad=-3.2485)], [Var(v=-0.0765, grad=0.0000)], [Var(v=0.0857, grad=0.0000)], [Var(v=-0.1022, grad=-1.9156)], [Var(v=-0.0438, grad=-1.7878)], [Var(v=-0.1811, grad=0.0000)], [Var(v=0.0177, grad=1.7847)], [Var(v=-0.0677, grad=1.9710)], [Var(v=0.2028, grad=-1.7170)], [Var(v=0.0291, grad=0.7488)], [Var(v=0.0397, grad=1.6018)], [Var(v=-0.0484, grad=-0.0171)], [Var(v=-0.0981, grad=0.0000)], [Var(v=0.0472, grad=1.7714)], [Var(v=0.1919, grad=-0.6199)], [Var(v=0.0155, grad=-0.0874)], [Var(v=0.1398, grad=0.3575)], [Var(v=0.0241, grad=0.5079)], [Var(v=0.0726, grad=0.0000)], [Var(v=0.0824, grad=-1.9066)], [Var(v=-0.0348, grad=-0.2896)], [Var(v=0.0836, grad=0.4336)], [Var(v=-0.0184, grad=-2.4176)], [Var(v=0.1214, grad=0.4890)], [Var(v=0.0471, grad=-1.6999)], [Var(v=-0.1514, grad=2.2041)], [Var(v=-0.0215, grad=-1.1272)], [Var(v=-0.0251, grad=0.0000)], [Var(v=-0.0818, grad=3.0282)], [Var(v=0.0018, grad=1.6263)], [Var(v=-0.0930, grad=0.0000)], [Var(v=-0.1197, grad=2.1492)], [Var(v=0.0576, grad=-1.6325)], [Var(v=0.0828, grad=-2.8622)], [Var(v=0.1321, grad=-3.1634)], [Var(v=0.0220, grad=0.0000)], [Var(v=0.0071, grad=0.0000)], [Var(v=-0.3135, grad=-0.4151)], [Var(v=-0.0748, grad=-0.1971)], [Var(v=0.0769, grad=-1.6683)], [Var(v=0.1047, grad=-3.8280)], [Var(v=0.0635, grad=0.0000)], [Var(v=0.0295, grad=1.4016)], [Var(v=0.0285, grad=-1.9585)], [Var(v=0.0065, grad=-1.8542)], [Var(v=0.0286, grad=0.6961)]] Biases: [Var(v=-0.0029, grad=0.2889)]\n",
            "\n",
            "Network after zeroing gradients:\n",
            "Layer 0 \n",
            " Weights: [[Var(v=-0.1043, grad=0.0000), Var(v=0.0944, grad=0.0000), Var(v=-0.0113, grad=0.0000), Var(v=-0.0700, grad=0.0000), Var(v=0.0539, grad=0.0000), Var(v=-0.1213, grad=0.0000), Var(v=-0.0458, grad=0.0000), Var(v=-0.0788, grad=0.0000), Var(v=0.0436, grad=0.0000), Var(v=0.1519, grad=0.0000), Var(v=0.1023, grad=0.0000), Var(v=-0.1405, grad=0.0000), Var(v=-0.1081, grad=0.0000), Var(v=0.1801, grad=0.0000), Var(v=0.1348, grad=0.0000)]] Biases: [Var(v=-0.1241, grad=0.0000), Var(v=0.0344, grad=0.0000), Var(v=-0.0645, grad=0.0000), Var(v=-0.0761, grad=0.0000), Var(v=0.0411, grad=0.0000), Var(v=-0.0061, grad=0.0000), Var(v=0.0003, grad=0.0000), Var(v=0.0098, grad=0.0000), Var(v=0.0325, grad=0.0000), Var(v=0.1063, grad=0.0000), Var(v=0.0005, grad=0.0000), Var(v=0.0048, grad=0.0000), Var(v=0.0186, grad=0.0000), Var(v=0.0560, grad=0.0000), Var(v=0.0414, grad=0.0000)]\n",
            "Layer 1 \n",
            " Weights: [[Var(v=0.0406, grad=0.0000), Var(v=-0.1137, grad=0.0000), Var(v=-0.1249, grad=0.0000), Var(v=0.1134, grad=0.0000), Var(v=0.1407, grad=0.0000), Var(v=0.0416, grad=0.0000), Var(v=-0.0372, grad=0.0000), Var(v=0.2180, grad=0.0000), Var(v=-0.0339, grad=0.0000), Var(v=-0.0584, grad=0.0000), Var(v=0.2616, grad=0.0000), Var(v=0.0707, grad=0.0000), Var(v=-0.0070, grad=0.0000), Var(v=0.1242, grad=0.0000), Var(v=-0.0397, grad=0.0000), Var(v=0.0194, grad=0.0000), Var(v=-0.2356, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0678, grad=0.0000), Var(v=0.0315, grad=0.0000), Var(v=-0.0830, grad=0.0000), Var(v=0.0106, grad=0.0000), Var(v=-0.0143, grad=0.0000), Var(v=-0.0528, grad=0.0000), Var(v=0.0243, grad=0.0000), Var(v=-0.0924, grad=0.0000), Var(v=0.2383, grad=0.0000), Var(v=-0.0349, grad=0.0000), Var(v=-0.0679, grad=0.0000), Var(v=-0.0983, grad=0.0000), Var(v=-0.0403, grad=0.0000), Var(v=0.0260, grad=0.0000), Var(v=0.1745, grad=0.0000), Var(v=-0.0335, grad=0.0000), Var(v=0.0637, grad=0.0000), Var(v=-0.0865, grad=0.0000), Var(v=-0.3215, grad=0.0000), Var(v=0.0067, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0880, grad=0.0000), Var(v=0.0498, grad=0.0000), Var(v=0.2170, grad=0.0000), Var(v=-0.0691, grad=0.0000), Var(v=-0.0432, grad=0.0000), Var(v=-0.0237, grad=0.0000), Var(v=-0.0621, grad=0.0000), Var(v=-0.0408, grad=0.0000), Var(v=-0.0578, grad=0.0000), Var(v=-0.0816, grad=0.0000), Var(v=-0.1089, grad=0.0000)], [Var(v=-0.0895, grad=0.0000), Var(v=-0.1364, grad=0.0000), Var(v=-0.1270, grad=0.0000), Var(v=0.0341, grad=0.0000), Var(v=-0.0039, grad=0.0000), Var(v=-0.0628, grad=0.0000), Var(v=-0.0728, grad=0.0000), Var(v=0.0262, grad=0.0000), Var(v=0.0107, grad=0.0000), Var(v=-0.1718, grad=0.0000), Var(v=0.0925, grad=0.0000), Var(v=-0.0286, grad=0.0000), Var(v=-0.0067, grad=0.0000), Var(v=-0.1494, grad=0.0000), Var(v=0.0271, grad=0.0000), Var(v=-0.0489, grad=0.0000), Var(v=-0.0973, grad=0.0000), Var(v=-0.0365, grad=0.0000), Var(v=0.0915, grad=0.0000), Var(v=0.0549, grad=0.0000), Var(v=0.0591, grad=0.0000), Var(v=0.0039, grad=0.0000), Var(v=-0.1213, grad=0.0000), Var(v=0.0787, grad=0.0000), Var(v=-0.0902, grad=0.0000), Var(v=-0.0025, grad=0.0000), Var(v=-0.0326, grad=0.0000), Var(v=-0.1256, grad=0.0000), Var(v=-0.0629, grad=0.0000), Var(v=0.1402, grad=0.0000), Var(v=0.0781, grad=0.0000), Var(v=-0.0787, grad=0.0000), Var(v=0.0850, grad=0.0000), Var(v=-0.1027, grad=0.0000), Var(v=-0.1323, grad=0.0000), Var(v=-0.0693, grad=0.0000), Var(v=0.1184, grad=0.0000), Var(v=0.1096, grad=0.0000), Var(v=-0.1766, grad=0.0000), Var(v=-0.0556, grad=0.0000), Var(v=-0.0954, grad=0.0000), Var(v=-0.1228, grad=0.0000), Var(v=0.0085, grad=0.0000), Var(v=0.0642, grad=0.0000), Var(v=-0.0895, grad=0.0000), Var(v=-0.0926, grad=0.0000), Var(v=0.1136, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=-0.1564, grad=0.0000), Var(v=0.1221, grad=0.0000)], [Var(v=0.0500, grad=0.0000), Var(v=-0.0801, grad=0.0000), Var(v=0.0031, grad=0.0000), Var(v=-0.0484, grad=0.0000), Var(v=0.1369, grad=0.0000), Var(v=0.1393, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0384, grad=0.0000), Var(v=0.0212, grad=0.0000), Var(v=-0.1093, grad=0.0000), Var(v=-0.0161, grad=0.0000), Var(v=-0.0278, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=0.1773, grad=0.0000), Var(v=-0.0183, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=-0.0190, grad=0.0000), Var(v=-0.0068, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=0.0658, grad=0.0000), Var(v=-0.0883, grad=0.0000), Var(v=-0.0628, grad=0.0000), Var(v=0.1525, grad=0.0000), Var(v=0.0701, grad=0.0000), Var(v=-0.0984, grad=0.0000), Var(v=-0.1773, grad=0.0000), Var(v=0.0674, grad=0.0000), Var(v=-0.0378, grad=0.0000), Var(v=0.0235, grad=0.0000), Var(v=0.2615, grad=0.0000), Var(v=0.1678, grad=0.0000), Var(v=-0.2148, grad=0.0000), Var(v=-0.0551, grad=0.0000), Var(v=-0.1286, grad=0.0000), Var(v=-0.1408, grad=0.0000), Var(v=-0.0273, grad=0.0000), Var(v=0.1195, grad=0.0000), Var(v=0.0375, grad=0.0000), Var(v=0.0870, grad=0.0000), Var(v=-0.0840, grad=0.0000), Var(v=-0.1704, grad=0.0000), Var(v=0.1677, grad=0.0000), Var(v=-0.0065, grad=0.0000), Var(v=-0.0906, grad=0.0000), Var(v=0.2261, grad=0.0000), Var(v=-0.0022, grad=0.0000), Var(v=-0.0942, grad=0.0000), Var(v=-0.1206, grad=0.0000), Var(v=0.0101, grad=0.0000), Var(v=-0.1595, grad=0.0000)], [Var(v=-0.2340, grad=0.0000), Var(v=0.0158, grad=0.0000), Var(v=-0.0082, grad=0.0000), Var(v=0.0006, grad=0.0000), Var(v=0.2681, grad=0.0000), Var(v=0.0200, grad=0.0000), Var(v=-0.0179, grad=0.0000), Var(v=0.0317, grad=0.0000), Var(v=0.0061, grad=0.0000), Var(v=-0.1148, grad=0.0000), Var(v=-0.1445, grad=0.0000), Var(v=-0.0793, grad=0.0000), Var(v=-0.0182, grad=0.0000), Var(v=0.0866, grad=0.0000), Var(v=0.1416, grad=0.0000), Var(v=0.0563, grad=0.0000), Var(v=-0.0729, grad=0.0000), Var(v=0.0762, grad=0.0000), Var(v=-0.1284, grad=0.0000), Var(v=0.1276, grad=0.0000), Var(v=0.0247, grad=0.0000), Var(v=0.1635, grad=0.0000), Var(v=0.0043, grad=0.0000), Var(v=-0.0371, grad=0.0000), Var(v=0.0999, grad=0.0000), Var(v=0.1110, grad=0.0000), Var(v=-0.1476, grad=0.0000), Var(v=-0.0933, grad=0.0000), Var(v=-0.0153, grad=0.0000), Var(v=-0.0103, grad=0.0000), Var(v=0.0156, grad=0.0000), Var(v=0.1673, grad=0.0000), Var(v=-0.0409, grad=0.0000), Var(v=0.0813, grad=0.0000), Var(v=-0.0832, grad=0.0000), Var(v=0.0587, grad=0.0000), Var(v=0.0914, grad=0.0000), Var(v=-0.0658, grad=0.0000), Var(v=-0.1171, grad=0.0000), Var(v=-0.1015, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=-0.0102, grad=0.0000), Var(v=0.0851, grad=0.0000), Var(v=-0.0146, grad=0.0000), Var(v=-0.2165, grad=0.0000), Var(v=-0.1781, grad=0.0000), Var(v=-0.0676, grad=0.0000), Var(v=0.0621, grad=0.0000), Var(v=0.1597, grad=0.0000), Var(v=-0.0018, grad=0.0000)], [Var(v=0.0475, grad=0.0000), Var(v=0.1124, grad=0.0000), Var(v=0.0389, grad=0.0000), Var(v=0.0344, grad=0.0000), Var(v=-0.0348, grad=0.0000), Var(v=0.1777, grad=0.0000), Var(v=0.0065, grad=0.0000), Var(v=-0.0891, grad=0.0000), Var(v=0.1201, grad=0.0000), Var(v=-0.0696, grad=0.0000), Var(v=0.1439, grad=0.0000), Var(v=-0.0091, grad=0.0000), Var(v=-0.0416, grad=0.0000), Var(v=-0.0785, grad=0.0000), Var(v=-0.1918, grad=0.0000), Var(v=0.0569, grad=0.0000), Var(v=0.0986, grad=0.0000), Var(v=0.0572, grad=0.0000), Var(v=0.1154, grad=0.0000), Var(v=-0.1691, grad=0.0000), Var(v=-0.0829, grad=0.0000), Var(v=-0.0342, grad=0.0000), Var(v=0.1496, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.1518, grad=0.0000), Var(v=-0.1923, grad=0.0000), Var(v=0.1106, grad=0.0000), Var(v=0.0148, grad=0.0000), Var(v=0.2283, grad=0.0000), Var(v=-0.0239, grad=0.0000), Var(v=0.1316, grad=0.0000), Var(v=-0.0023, grad=0.0000), Var(v=0.0057, grad=0.0000), Var(v=0.0401, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=0.0771, grad=0.0000), Var(v=-0.0725, grad=0.0000), Var(v=0.0762, grad=0.0000), Var(v=0.1208, grad=0.0000), Var(v=-0.0196, grad=0.0000), Var(v=0.0091, grad=0.0000), Var(v=-0.1120, grad=0.0000), Var(v=0.1205, grad=0.0000), Var(v=0.0720, grad=0.0000), Var(v=0.0036, grad=0.0000), Var(v=0.0244, grad=0.0000), Var(v=-0.0199, grad=0.0000), Var(v=0.0104, grad=0.0000), Var(v=-0.0087, grad=0.0000), Var(v=0.0291, grad=0.0000)], [Var(v=0.0190, grad=0.0000), Var(v=-0.0149, grad=0.0000), Var(v=-0.2697, grad=0.0000), Var(v=-0.0151, grad=0.0000), Var(v=0.0082, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=0.0079, grad=0.0000), Var(v=-0.0378, grad=0.0000), Var(v=-0.1322, grad=0.0000), Var(v=-0.0050, grad=0.0000), Var(v=0.0724, grad=0.0000), Var(v=-0.0480, grad=0.0000), Var(v=-0.1327, grad=0.0000), Var(v=-0.0858, grad=0.0000), Var(v=0.0296, grad=0.0000), Var(v=0.0154, grad=0.0000), Var(v=-0.0581, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=-0.1174, grad=0.0000), Var(v=-0.0758, grad=0.0000), Var(v=0.0178, grad=0.0000), Var(v=-0.0117, grad=0.0000), Var(v=-0.0579, grad=0.0000), Var(v=0.0367, grad=0.0000), Var(v=0.0849, grad=0.0000), Var(v=0.0802, grad=0.0000), Var(v=-0.0578, grad=0.0000), Var(v=0.0518, grad=0.0000), Var(v=0.0205, grad=0.0000), Var(v=0.1485, grad=0.0000), Var(v=-0.0428, grad=0.0000), Var(v=-0.1502, grad=0.0000), Var(v=0.2506, grad=0.0000), Var(v=0.0184, grad=0.0000), Var(v=-0.2234, grad=0.0000), Var(v=0.0115, grad=0.0000), Var(v=0.1386, grad=0.0000), Var(v=0.0116, grad=0.0000), Var(v=-0.1382, grad=0.0000), Var(v=-0.1641, grad=0.0000), Var(v=0.0055, grad=0.0000), Var(v=-0.0238, grad=0.0000), Var(v=-0.0061, grad=0.0000), Var(v=0.0241, grad=0.0000), Var(v=-0.1647, grad=0.0000), Var(v=-0.0167, grad=0.0000), Var(v=0.0972, grad=0.0000), Var(v=-0.0752, grad=0.0000), Var(v=-0.0395, grad=0.0000), Var(v=0.0113, grad=0.0000)], [Var(v=0.1675, grad=0.0000), Var(v=0.0626, grad=0.0000), Var(v=0.0705, grad=0.0000), Var(v=-0.0261, grad=0.0000), Var(v=0.0072, grad=0.0000), Var(v=0.0339, grad=0.0000), Var(v=0.0695, grad=0.0000), Var(v=-0.0655, grad=0.0000), Var(v=0.0682, grad=0.0000), Var(v=-0.0135, grad=0.0000), Var(v=0.0366, grad=0.0000), Var(v=-0.0596, grad=0.0000), Var(v=0.0189, grad=0.0000), Var(v=0.1662, grad=0.0000), Var(v=0.1154, grad=0.0000), Var(v=0.0650, grad=0.0000), Var(v=0.0117, grad=0.0000), Var(v=0.0565, grad=0.0000), Var(v=-0.1200, grad=0.0000), Var(v=-0.1723, grad=0.0000), Var(v=-0.1196, grad=0.0000), Var(v=0.1146, grad=0.0000), Var(v=-0.0338, grad=0.0000), Var(v=0.0327, grad=0.0000), Var(v=-0.0776, grad=0.0000), Var(v=-0.1913, grad=0.0000), Var(v=0.0911, grad=0.0000), Var(v=0.0071, grad=0.0000), Var(v=0.0718, grad=0.0000), Var(v=-0.0237, grad=0.0000), Var(v=0.0589, grad=0.0000), Var(v=0.0018, grad=0.0000), Var(v=0.0707, grad=0.0000), Var(v=-0.2083, grad=0.0000), Var(v=-0.0130, grad=0.0000), Var(v=0.0662, grad=0.0000), Var(v=0.1460, grad=0.0000), Var(v=0.1142, grad=0.0000), Var(v=0.0429, grad=0.0000), Var(v=-0.1112, grad=0.0000), Var(v=0.1543, grad=0.0000), Var(v=-0.1496, grad=0.0000), Var(v=-0.1245, grad=0.0000), Var(v=0.2003, grad=0.0000), Var(v=0.0206, grad=0.0000), Var(v=0.0871, grad=0.0000), Var(v=0.1800, grad=0.0000), Var(v=-0.1267, grad=0.0000), Var(v=0.0476, grad=0.0000), Var(v=0.0600, grad=0.0000)], [Var(v=-0.0738, grad=0.0000), Var(v=0.0766, grad=0.0000), Var(v=-0.0244, grad=0.0000), Var(v=0.0013, grad=0.0000), Var(v=-0.0891, grad=0.0000), Var(v=-0.1327, grad=0.0000), Var(v=-0.0973, grad=0.0000), Var(v=-0.1091, grad=0.0000), Var(v=-0.0033, grad=0.0000), Var(v=-0.0402, grad=0.0000), Var(v=-0.0907, grad=0.0000), Var(v=0.0687, grad=0.0000), Var(v=0.0840, grad=0.0000), Var(v=0.2189, grad=0.0000), Var(v=0.0070, grad=0.0000), Var(v=0.0410, grad=0.0000), Var(v=-0.1012, grad=0.0000), Var(v=0.1113, grad=0.0000), Var(v=0.0681, grad=0.0000), Var(v=-0.1316, grad=0.0000), Var(v=-0.0726, grad=0.0000), Var(v=0.1010, grad=0.0000), Var(v=0.0019, grad=0.0000), Var(v=-0.0458, grad=0.0000), Var(v=-0.0785, grad=0.0000), Var(v=0.0993, grad=0.0000), Var(v=-0.0335, grad=0.0000), Var(v=0.0540, grad=0.0000), Var(v=-0.0008, grad=0.0000), Var(v=0.0765, grad=0.0000), Var(v=0.2007, grad=0.0000), Var(v=-0.0590, grad=0.0000), Var(v=0.0353, grad=0.0000), Var(v=0.1022, grad=0.0000), Var(v=0.0805, grad=0.0000), Var(v=0.0057, grad=0.0000), Var(v=0.0134, grad=0.0000), Var(v=-0.2039, grad=0.0000), Var(v=-0.0287, grad=0.0000), Var(v=-0.0186, grad=0.0000), Var(v=0.0508, grad=0.0000), Var(v=0.1460, grad=0.0000), Var(v=0.0649, grad=0.0000), Var(v=-0.0437, grad=0.0000), Var(v=-0.0341, grad=0.0000), Var(v=-0.3720, grad=0.0000), Var(v=-0.1212, grad=0.0000), Var(v=0.0052, grad=0.0000), Var(v=0.1017, grad=0.0000), Var(v=0.0405, grad=0.0000)], [Var(v=-0.1843, grad=0.0000), Var(v=0.0530, grad=0.0000), Var(v=0.0268, grad=0.0000), Var(v=-0.0690, grad=0.0000), Var(v=0.2684, grad=0.0000), Var(v=-0.0283, grad=0.0000), Var(v=-0.0583, grad=0.0000), Var(v=-0.1576, grad=0.0000), Var(v=0.0088, grad=0.0000), Var(v=0.0027, grad=0.0000), Var(v=-0.1529, grad=0.0000), Var(v=0.0365, grad=0.0000), Var(v=0.1208, grad=0.0000), Var(v=0.1476, grad=0.0000), Var(v=-0.0538, grad=0.0000), Var(v=0.1000, grad=0.0000), Var(v=0.0713, grad=0.0000), Var(v=-0.0231, grad=0.0000), Var(v=0.0482, grad=0.0000), Var(v=0.0253, grad=0.0000), Var(v=0.0869, grad=0.0000), Var(v=0.1311, grad=0.0000), Var(v=0.0041, grad=0.0000), Var(v=0.0037, grad=0.0000), Var(v=0.0517, grad=0.0000), Var(v=-0.0445, grad=0.0000), Var(v=-0.0383, grad=0.0000), Var(v=0.0331, grad=0.0000), Var(v=0.1290, grad=0.0000), Var(v=-0.0250, grad=0.0000), Var(v=-0.0471, grad=0.0000), Var(v=-0.1743, grad=0.0000), Var(v=-0.1957, grad=0.0000), Var(v=-0.0595, grad=0.0000), Var(v=-0.0840, grad=0.0000), Var(v=0.0899, grad=0.0000), Var(v=-0.0380, grad=0.0000), Var(v=0.1464, grad=0.0000), Var(v=-0.0773, grad=0.0000), Var(v=-0.0492, grad=0.0000), Var(v=-0.0442, grad=0.0000), Var(v=0.0561, grad=0.0000), Var(v=0.0270, grad=0.0000), Var(v=0.0534, grad=0.0000), Var(v=0.0660, grad=0.0000), Var(v=-0.1151, grad=0.0000), Var(v=0.2603, grad=0.0000), Var(v=0.0004, grad=0.0000), Var(v=-0.0591, grad=0.0000), Var(v=0.1215, grad=0.0000)], [Var(v=-0.0182, grad=0.0000), Var(v=0.0093, grad=0.0000), Var(v=-0.0193, grad=0.0000), Var(v=0.0290, grad=0.0000), Var(v=-0.1169, grad=0.0000), Var(v=-0.0805, grad=0.0000), Var(v=-0.0318, grad=0.0000), Var(v=-0.0621, grad=0.0000), Var(v=0.0259, grad=0.0000), Var(v=-0.0359, grad=0.0000), Var(v=0.0794, grad=0.0000), Var(v=0.0140, grad=0.0000), Var(v=0.0372, grad=0.0000), Var(v=-0.0137, grad=0.0000), Var(v=-0.0213, grad=0.0000), Var(v=-0.1370, grad=0.0000), Var(v=0.0186, grad=0.0000), Var(v=-0.0653, grad=0.0000), Var(v=0.2977, grad=0.0000), Var(v=0.0449, grad=0.0000), Var(v=-0.0305, grad=0.0000), Var(v=0.0055, grad=0.0000), Var(v=-0.0270, grad=0.0000), Var(v=0.2485, grad=0.0000), Var(v=-0.0507, grad=0.0000), Var(v=-0.0518, grad=0.0000), Var(v=0.0785, grad=0.0000), Var(v=-0.1970, grad=0.0000), Var(v=-0.0591, grad=0.0000), Var(v=0.1257, grad=0.0000), Var(v=0.1131, grad=0.0000), Var(v=0.1515, grad=0.0000), Var(v=0.0144, grad=0.0000), Var(v=-0.0539, grad=0.0000), Var(v=0.0356, grad=0.0000), Var(v=0.0355, grad=0.0000), Var(v=-0.0657, grad=0.0000), Var(v=-0.0600, grad=0.0000), Var(v=-0.0857, grad=0.0000), Var(v=-0.1654, grad=0.0000), Var(v=0.0631, grad=0.0000), Var(v=-0.1380, grad=0.0000), Var(v=-0.0564, grad=0.0000), Var(v=0.0257, grad=0.0000), Var(v=-0.0116, grad=0.0000), Var(v=-0.0108, grad=0.0000), Var(v=-0.0218, grad=0.0000), Var(v=-0.0124, grad=0.0000), Var(v=0.0209, grad=0.0000), Var(v=0.2518, grad=0.0000)], [Var(v=-0.0665, grad=0.0000), Var(v=0.0719, grad=0.0000), Var(v=0.0306, grad=0.0000), Var(v=0.0818, grad=0.0000), Var(v=-0.1195, grad=0.0000), Var(v=-0.0642, grad=0.0000), Var(v=0.0449, grad=0.0000), Var(v=0.0587, grad=0.0000), Var(v=0.1576, grad=0.0000), Var(v=0.1338, grad=0.0000), Var(v=0.0290, grad=0.0000), Var(v=-0.2667, grad=0.0000), Var(v=-0.0537, grad=0.0000), Var(v=-0.0364, grad=0.0000), Var(v=-0.0360, grad=0.0000), Var(v=0.0305, grad=0.0000), Var(v=0.0451, grad=0.0000), Var(v=-0.1342, grad=0.0000), Var(v=0.0717, grad=0.0000), Var(v=-0.0052, grad=0.0000), Var(v=-0.0882, grad=0.0000), Var(v=-0.0144, grad=0.0000), Var(v=-0.1023, grad=0.0000), Var(v=-0.1044, grad=0.0000), Var(v=0.1261, grad=0.0000), Var(v=0.0066, grad=0.0000), Var(v=0.0465, grad=0.0000), Var(v=0.0076, grad=0.0000), Var(v=0.0155, grad=0.0000), Var(v=-0.0349, grad=0.0000), Var(v=0.0656, grad=0.0000), Var(v=-0.1068, grad=0.0000), Var(v=-0.1779, grad=0.0000), Var(v=-0.0530, grad=0.0000), Var(v=0.1469, grad=0.0000), Var(v=-0.1518, grad=0.0000), Var(v=-0.0533, grad=0.0000), Var(v=0.1341, grad=0.0000), Var(v=0.1928, grad=0.0000), Var(v=-0.0874, grad=0.0000), Var(v=-0.1262, grad=0.0000), Var(v=0.0299, grad=0.0000), Var(v=-0.0539, grad=0.0000), Var(v=0.0274, grad=0.0000), Var(v=0.0877, grad=0.0000), Var(v=0.0633, grad=0.0000), Var(v=0.1303, grad=0.0000), Var(v=0.1044, grad=0.0000), Var(v=-0.0748, grad=0.0000), Var(v=-0.1349, grad=0.0000)], [Var(v=-0.1103, grad=0.0000), Var(v=-0.1065, grad=0.0000), Var(v=-0.1260, grad=0.0000), Var(v=-0.1211, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=-0.0786, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=0.0700, grad=0.0000), Var(v=-0.0507, grad=0.0000), Var(v=-0.0521, grad=0.0000), Var(v=0.0618, grad=0.0000), Var(v=0.1317, grad=0.0000), Var(v=0.0663, grad=0.0000), Var(v=-0.0487, grad=0.0000), Var(v=0.0641, grad=0.0000), Var(v=0.0571, grad=0.0000), Var(v=-0.0294, grad=0.0000), Var(v=-0.0209, grad=0.0000), Var(v=0.0698, grad=0.0000), Var(v=-0.0282, grad=0.0000), Var(v=0.0450, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=-0.0304, grad=0.0000), Var(v=-0.0557, grad=0.0000), Var(v=0.0173, grad=0.0000), Var(v=0.0660, grad=0.0000), Var(v=0.1075, grad=0.0000), Var(v=-0.0752, grad=0.0000), Var(v=0.0377, grad=0.0000), Var(v=-0.0180, grad=0.0000), Var(v=0.2256, grad=0.0000), Var(v=-0.0508, grad=0.0000), Var(v=0.0916, grad=0.0000), Var(v=0.0932, grad=0.0000), Var(v=0.0176, grad=0.0000), Var(v=0.0677, grad=0.0000), Var(v=-0.2674, grad=0.0000), Var(v=0.0832, grad=0.0000), Var(v=-0.1129, grad=0.0000), Var(v=-0.1468, grad=0.0000), Var(v=-0.0914, grad=0.0000), Var(v=-0.0977, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=-0.0885, grad=0.0000), Var(v=0.0679, grad=0.0000), Var(v=-0.1683, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=-0.0799, grad=0.0000), Var(v=0.0758, grad=0.0000), Var(v=-0.0086, grad=0.0000)], [Var(v=0.0338, grad=0.0000), Var(v=-0.0516, grad=0.0000), Var(v=-0.0059, grad=0.0000), Var(v=0.0513, grad=0.0000), Var(v=-0.1166, grad=0.0000), Var(v=0.0652, grad=0.0000), Var(v=-0.0888, grad=0.0000), Var(v=-0.0387, grad=0.0000), Var(v=-0.0911, grad=0.0000), Var(v=0.0544, grad=0.0000), Var(v=0.0777, grad=0.0000), Var(v=0.1051, grad=0.0000), Var(v=-0.0912, grad=0.0000), Var(v=0.0545, grad=0.0000), Var(v=-0.0465, grad=0.0000), Var(v=-0.0078, grad=0.0000), Var(v=-0.1435, grad=0.0000), Var(v=0.0313, grad=0.0000), Var(v=-0.0077, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=-0.0112, grad=0.0000), Var(v=0.0197, grad=0.0000), Var(v=-0.1625, grad=0.0000), Var(v=0.0250, grad=0.0000), Var(v=-0.0079, grad=0.0000), Var(v=-0.1925, grad=0.0000), Var(v=-0.1290, grad=0.0000), Var(v=-0.0147, grad=0.0000), Var(v=-0.1429, grad=0.0000), Var(v=0.0957, grad=0.0000), Var(v=-0.3121, grad=0.0000), Var(v=-0.0327, grad=0.0000), Var(v=-0.0796, grad=0.0000), Var(v=0.0421, grad=0.0000), Var(v=0.0134, grad=0.0000), Var(v=0.1488, grad=0.0000), Var(v=-0.0619, grad=0.0000), Var(v=-0.0616, grad=0.0000), Var(v=0.0580, grad=0.0000), Var(v=-0.1770, grad=0.0000), Var(v=-0.0492, grad=0.0000), Var(v=-0.2561, grad=0.0000), Var(v=-0.0652, grad=0.0000), Var(v=-0.1107, grad=0.0000), Var(v=0.0237, grad=0.0000), Var(v=0.0301, grad=0.0000), Var(v=0.0688, grad=0.0000), Var(v=0.1355, grad=0.0000), Var(v=-0.0687, grad=0.0000), Var(v=-0.0019, grad=0.0000)], [Var(v=-0.0215, grad=0.0000), Var(v=-0.1893, grad=0.0000), Var(v=-0.0775, grad=0.0000), Var(v=-0.0139, grad=0.0000), Var(v=0.1503, grad=0.0000), Var(v=-0.0036, grad=0.0000), Var(v=-0.0864, grad=0.0000), Var(v=0.1226, grad=0.0000), Var(v=0.0154, grad=0.0000), Var(v=-0.1851, grad=0.0000), Var(v=-0.0378, grad=0.0000), Var(v=-0.1727, grad=0.0000), Var(v=0.2579, grad=0.0000), Var(v=-0.1408, grad=0.0000), Var(v=0.0540, grad=0.0000), Var(v=0.1791, grad=0.0000), Var(v=0.0251, grad=0.0000), Var(v=0.1406, grad=0.0000), Var(v=0.0170, grad=0.0000), Var(v=0.0787, grad=0.0000), Var(v=-0.1107, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=-0.1486, grad=0.0000), Var(v=0.0715, grad=0.0000), Var(v=-0.0280, grad=0.0000), Var(v=-0.0261, grad=0.0000), Var(v=-0.0106, grad=0.0000), Var(v=0.0239, grad=0.0000), Var(v=0.1783, grad=0.0000), Var(v=-0.1024, grad=0.0000), Var(v=0.0456, grad=0.0000), Var(v=0.0786, grad=0.0000), Var(v=0.2147, grad=0.0000), Var(v=0.1578, grad=0.0000), Var(v=-0.0171, grad=0.0000), Var(v=-0.0192, grad=0.0000), Var(v=0.1303, grad=0.0000), Var(v=0.1023, grad=0.0000), Var(v=0.1227, grad=0.0000), Var(v=0.0320, grad=0.0000), Var(v=-0.0628, grad=0.0000), Var(v=-0.1351, grad=0.0000), Var(v=-0.0288, grad=0.0000), Var(v=0.1059, grad=0.0000), Var(v=0.2272, grad=0.0000), Var(v=-0.0564, grad=0.0000), Var(v=-0.0392, grad=0.0000), Var(v=0.1064, grad=0.0000), Var(v=0.2693, grad=0.0000), Var(v=-0.0147, grad=0.0000)], [Var(v=-0.0014, grad=0.0000), Var(v=0.0276, grad=0.0000), Var(v=0.0045, grad=0.0000), Var(v=-0.0352, grad=0.0000), Var(v=0.0777, grad=0.0000), Var(v=-0.0524, grad=0.0000), Var(v=-0.0042, grad=0.0000), Var(v=-0.1862, grad=0.0000), Var(v=-0.0560, grad=0.0000), Var(v=-0.1376, grad=0.0000), Var(v=-0.0973, grad=0.0000), Var(v=0.0002, grad=0.0000), Var(v=0.0437, grad=0.0000), Var(v=0.1734, grad=0.0000), Var(v=-0.0472, grad=0.0000), Var(v=-0.1321, grad=0.0000), Var(v=-0.0285, grad=0.0000), Var(v=-0.0394, grad=0.0000), Var(v=-0.0428, grad=0.0000), Var(v=-0.2107, grad=0.0000), Var(v=-0.0115, grad=0.0000), Var(v=0.1156, grad=0.0000), Var(v=0.1044, grad=0.0000), Var(v=0.1385, grad=0.0000), Var(v=0.0236, grad=0.0000), Var(v=-0.0251, grad=0.0000), Var(v=0.0768, grad=0.0000), Var(v=-0.0453, grad=0.0000), Var(v=0.0055, grad=0.0000), Var(v=-0.1391, grad=0.0000), Var(v=-0.0876, grad=0.0000), Var(v=0.0908, grad=0.0000), Var(v=-0.0783, grad=0.0000), Var(v=-0.0853, grad=0.0000), Var(v=-0.1653, grad=0.0000), Var(v=0.0976, grad=0.0000), Var(v=0.0923, grad=0.0000), Var(v=-0.0083, grad=0.0000), Var(v=0.1060, grad=0.0000), Var(v=-0.0154, grad=0.0000), Var(v=-0.0370, grad=0.0000), Var(v=-0.0556, grad=0.0000), Var(v=0.1090, grad=0.0000), Var(v=0.0793, grad=0.0000), Var(v=0.0111, grad=0.0000), Var(v=-0.1514, grad=0.0000), Var(v=0.0465, grad=0.0000), Var(v=0.0085, grad=0.0000), Var(v=0.1134, grad=0.0000), Var(v=-0.1156, grad=0.0000)]] Biases: [Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0457, grad=0.0000), Var(v=-0.0663, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.1053, grad=0.0000), Var(v=-0.0535, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=0.0418, grad=0.0000), Var(v=0.1610, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=-0.0485, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0565, grad=0.0000), Var(v=0.1611, grad=0.0000), Var(v=0.0127, grad=0.0000), Var(v=-0.1248, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0002, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=-0.0766, grad=0.0000), Var(v=-0.0369, grad=0.0000), Var(v=-0.1099, grad=0.0000), Var(v=0.0262, grad=0.0000), Var(v=0.1126, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0001, grad=0.0000), Var(v=-0.0157, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0855, grad=0.0000), Var(v=0.0358, grad=0.0000), Var(v=-0.0002, grad=0.0000), Var(v=0.0872, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.2756, grad=0.0000), Var(v=-0.0666, grad=0.0000), Var(v=0.0523, grad=0.0000), Var(v=0.0576, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0001, grad=0.0000), Var(v=0.0077, grad=0.0000), Var(v=0.0000, grad=0.0000), Var(v=-0.0309, grad=0.0000)]\n",
            "Layer 2 \n",
            " Weights: [[Var(v=-0.0645, grad=0.0000)], [Var(v=0.1794, grad=0.0000)], [Var(v=-0.0090, grad=0.0000)], [Var(v=0.0581, grad=0.0000)], [Var(v=-0.0440, grad=0.0000)], [Var(v=-0.0765, grad=0.0000)], [Var(v=0.0857, grad=0.0000)], [Var(v=-0.1022, grad=0.0000)], [Var(v=-0.0438, grad=0.0000)], [Var(v=-0.1811, grad=0.0000)], [Var(v=0.0177, grad=0.0000)], [Var(v=-0.0677, grad=0.0000)], [Var(v=0.2028, grad=0.0000)], [Var(v=0.0291, grad=0.0000)], [Var(v=0.0397, grad=0.0000)], [Var(v=-0.0484, grad=0.0000)], [Var(v=-0.0981, grad=0.0000)], [Var(v=0.0472, grad=0.0000)], [Var(v=0.1919, grad=0.0000)], [Var(v=0.0155, grad=0.0000)], [Var(v=0.1398, grad=0.0000)], [Var(v=0.0241, grad=0.0000)], [Var(v=0.0726, grad=0.0000)], [Var(v=0.0824, grad=0.0000)], [Var(v=-0.0348, grad=0.0000)], [Var(v=0.0836, grad=0.0000)], [Var(v=-0.0184, grad=0.0000)], [Var(v=0.1214, grad=0.0000)], [Var(v=0.0471, grad=0.0000)], [Var(v=-0.1514, grad=0.0000)], [Var(v=-0.0215, grad=0.0000)], [Var(v=-0.0251, grad=0.0000)], [Var(v=-0.0818, grad=0.0000)], [Var(v=0.0018, grad=0.0000)], [Var(v=-0.0930, grad=0.0000)], [Var(v=-0.1197, grad=0.0000)], [Var(v=0.0576, grad=0.0000)], [Var(v=0.0828, grad=0.0000)], [Var(v=0.1321, grad=0.0000)], [Var(v=0.0220, grad=0.0000)], [Var(v=0.0071, grad=0.0000)], [Var(v=-0.3135, grad=0.0000)], [Var(v=-0.0748, grad=0.0000)], [Var(v=0.0769, grad=0.0000)], [Var(v=0.1047, grad=0.0000)], [Var(v=0.0635, grad=0.0000)], [Var(v=0.0295, grad=0.0000)], [Var(v=0.0285, grad=0.0000)], [Var(v=0.0065, grad=0.0000)], [Var(v=0.0286, grad=0.0000)]] Biases: [Var(v=-0.0029, grad=0.0000)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "print('Network before update:')\n",
        "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
        "\n",
        "def parameters(network):\n",
        "  params = []\n",
        "  for layer in range(len(network)):\n",
        "    params += network[layer].parameters()\n",
        "  return params\n",
        "\n",
        "def update_parameters(params, learning_rate=0.01):\n",
        "  for p in params:\n",
        "    p.v -= learning_rate*p.grad\n",
        "\n",
        "def zero_gradients(params):\n",
        "  for p in params:\n",
        "    p.grad = 0.0\n",
        "\n",
        "update_parameters(parameters(NN))\n",
        "\n",
        "print('\\nNetwork after update:')\n",
        "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] \n",
        "\n",
        "zero_gradients(parameters(NN))\n",
        "\n",
        "print('\\nNetwork after zeroing gradients:')\n",
        "[print('Layer', i, '\\n', NN[i]) for i in range(len(NN))] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "woWYpdw6FtIO"
      },
      "outputs": [],
      "source": [
        "# Initialize an arbitrary neural network\n",
        "NN = [\n",
        "    DenseLayer(1, 8, lambda x: x.relu()),\n",
        "    DenseLayer(8, 1, lambda x: x.identity())\n",
        "]\n",
        "\n",
        "# Recommended hyper-parameters for 3-D: \n",
        "#NN = [\n",
        "#    DenseLayer(3, 16, lambda x: x.relu()),\n",
        "#    DenseLayer(16, 1, lambda x: x.identity())\n",
        "#]\n",
        "\n",
        "\n",
        "### Notice that, when we switch from tanh to relu activation, we decrease the learning rate. This is due the stability of the gradients \n",
        "## of the activation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mdqaqYBVFtIR"
      },
      "outputs": [],
      "source": [
        "# Initialize training hyperparameters\n",
        "EPOCHS = 200\n",
        "LEARN_R = 2e-3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5kfg76GMFtIW",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9616dd-8657-4f2b-d3dc-286de5062754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0 ( 0.00%) Train loss: 108.410 \t Validation loss: 108.322\n",
            "  10 ( 5.00%) Train loss: 45.174 \t Validation loss: 33.543\n",
            "  20 (10.00%) Train loss: 14.076 \t Validation loss: 10.713\n",
            "  30 (15.00%) Train loss: 13.615 \t Validation loss: 10.340\n",
            "  40 (20.00%) Train loss: 13.079 \t Validation loss: 9.886\n",
            "  50 (25.00%) Train loss: 12.765 \t Validation loss: 9.571\n",
            "  60 (30.00%) Train loss: 12.577 \t Validation loss: 9.362\n",
            "  70 (35.00%) Train loss: 12.376 \t Validation loss: 9.162\n",
            "  80 (40.00%) Train loss: 12.231 \t Validation loss: 9.008\n",
            "  90 (45.00%) Train loss: 12.094 \t Validation loss: 8.915\n",
            " 100 (50.00%) Train loss: 11.993 \t Validation loss: 8.848\n",
            " 110 (55.00%) Train loss: 11.946 \t Validation loss: 8.834\n",
            " 120 (60.00%) Train loss: 11.916 \t Validation loss: 8.855\n",
            " 130 (65.00%) Train loss: 11.898 \t Validation loss: 8.883\n",
            " 140 (70.00%) Train loss: 11.887 \t Validation loss: 8.904\n",
            " 150 (75.00%) Train loss: 11.880 \t Validation loss: 8.920\n",
            " 160 (80.00%) Train loss: 11.875 \t Validation loss: 8.934\n",
            " 170 (85.00%) Train loss: 11.871 \t Validation loss: 8.944\n",
            " 180 (90.00%) Train loss: 11.867 \t Validation loss: 8.949\n",
            " 190 (95.00%) Train loss: 11.865 \t Validation loss: 8.949\n"
          ]
        }
      ],
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "     \n",
        "    # Forward pass and loss computation\n",
        "    Loss = squared_loss(y_train, forward(x_train, NN))\n",
        "\n",
        "    # Backward pass\n",
        "    Loss.backward()\n",
        "    \n",
        "    # gradient descent update\n",
        "    update_parameters(parameters(NN), LEARN_R)\n",
        "    zero_gradients(parameters(NN))\n",
        "    \n",
        "    # Training loss\n",
        "    train_loss.append(Loss.v)\n",
        "    \n",
        "    # Validation\n",
        "    Loss_validation = squared_loss(y_validation, forward(x_validation, NN))\n",
        "    val_loss.append(Loss_validation.v)\n",
        "    \n",
        "    if e%10==0:\n",
        "        print(\"{:4d}\".format(e),\n",
        "              \"({:5.2f}%)\".format(e/EPOCHS*100), \n",
        "              \"Train loss: {:4.3f} \\t Validation loss: {:4.3f}\".format(train_loss[-1], val_loss[-1]))\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VetyRWFwFtIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "86a5cf3e-d121-4063-d763-af85411cc188"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(range(len(train_loss)), train_loss);\n",
        "plt.plot(range(len(val_loss)), val_loss);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OgmIrM9FtIb"
      },
      "source": [
        "# Testing\n",
        "\n",
        "We have kept the calculation of the test error separate in order to emphasize that you should not use the test set in optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HmNi7S-vFtIc"
      },
      "outputs": [],
      "source": [
        "output_test = forward(x_test, NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7mmJOTSEFtIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "ef436315-1cdb-4097-c1d9-694f0241bdcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  9.770\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "y_test_np = Var_to_nparray(y_test)\n",
        "plt.scatter(y_test_np, Var_to_nparray(output_test));\n",
        "plt.plot([np.min(y_test_np), np.max(y_test_np)], [np.min(y_test_np), np.max(y_test_np)], color='k');\n",
        "plt.xlabel(\"y\");\n",
        "plt.ylabel(\"$\\hat{y}$\");\n",
        "plt.title(\"Model prediction vs real in the test set, the close to the line the better\")\n",
        "plt.grid(True);\n",
        "plt.axis('equal');\n",
        "plt.tight_layout();\n",
        "\n",
        "Loss_test = squared_loss(y_test, forward(x_test, NN))\n",
        "\n",
        "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ODi0WlmQFtIh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "37d861c6-8934-4483-e04f-abd675cd2c26"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x_test_np = Var_to_nparray(x_test)\n",
        "x_train_np = Var_to_nparray(x_train)\n",
        "y_train_np = Var_to_nparray(y_train)\n",
        "if D1:\n",
        "    plt.scatter(x_train_np, y_train_np, label=\"train data\");\n",
        "    plt.scatter(x_test_np, Var_to_nparray(output_test), label=\"test prediction\");\n",
        "    plt.scatter(x_test_np, y_test_np, label=\"test data\");\n",
        "    plt.legend();\n",
        "    plt.xlabel(\"x\");\n",
        "    plt.ylabel(\"y\");\n",
        "else:\n",
        "    plt.scatter(x_train_np[:,1], y_train, label=\"train data\");\n",
        "    plt.scatter(x_test_np[:,1], Var_to_nparray(output_test), label=\"test data prediction\");\n",
        "    plt.scatter(x_test_np[:,1], y_test_np, label=\"test data\");\n",
        "    plt.legend();\n",
        "    plt.xlabel(\"x\");\n",
        "    plt.ylabel(\"y\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTBAmjsAFtIk"
      },
      "source": [
        "## Exercise l) Show overfitting, underfitting and just right fitting\n",
        "\n",
        "Vary the architecture and other things to show clear signs of overfitting (=training loss significantly lower than test loss) and underfitting (=not fitting enoung to training data so that test performance is also hurt).\n",
        "\n",
        "See also if you can get a good compromise which leads to a low validation loss. \n",
        "\n",
        "For this problem do you see any big difference between validation and test loss? The answer here will probably be no. Discuss cases where it is important to keep the two separate.\n",
        "\n",
        "_Insert written answer here._  \n",
        "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "\n",
        "\n",
        "A training loss defines how well our model fits training data, while the validation loss indicates how well our model fits with new data. A high validation loss means that we have overfitted, which we do not want. The optimal fit is when the graphs for the training and test loss/validation loss is on top of each other as above. Hence this could also means underfitting.\n",
        "\n",
        "Underfitting is when training loss is much higher than testing loss.\n",
        "Overfits is when training loss is much smaller than testing loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting"
      ],
      "metadata": {
        "id": "f-c4aUl6y_0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQZCn2dxFtIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32bb237-71fe-43f8-d5a6-a0c3ffd1ef9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0 ( 0.00%) Train loss: 103.192 \t Validation loss: 97.198\n"
          ]
        }
      ],
      "source": [
        "# Overfitting\n",
        "NN = [\n",
        "    DenseLayer(1, 20, lambda x: x.relu()),\n",
        "    DenseLayer(20, 1, lambda x: x.identity())\n",
        "]\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "# Initialize training hyperparameters\n",
        "EPOCHS = 300\n",
        "LEARN_R = 2e-3 \n",
        "\n",
        "for e in range(EPOCHS):\n",
        "     \n",
        "    # Forward pass and loss computation\n",
        "    Loss = squared_loss(y_train, forward(x_train, NN))\n",
        "\n",
        "    # Backward pass\n",
        "    Loss.backward()\n",
        "    \n",
        "    # gradient descent update\n",
        "    update_parameters(parameters(NN), LEARN_R)\n",
        "    zero_gradients(parameters(NN))\n",
        "    \n",
        "    # Training loss\n",
        "    train_loss.append(Loss.v)\n",
        "    \n",
        "    # Validation\n",
        "    Loss_validation = squared_loss(y_validation, forward(x_validation, NN))\n",
        "    val_loss.append(Loss_validation.v)\n",
        "    \n",
        "    if e%10==0:\n",
        "        print(\"{:4d}\".format(e),\n",
        "              \"({:5.2f}%)\".format(e/EPOCHS*100), \n",
        "              \"Train loss: {:4.3f} \\t Validation loss: {:4.3f}\".format(train_loss[-1], val_loss[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_loss)), train_loss);\n",
        "plt.plot(range(len(val_loss)), val_loss);\n",
        "plt.legend(loc=1, fontsize=16, labels = [\"Training loss\", \"Validation loss\"])\n",
        "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fuc8hUOV3lrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_test = forward(x_test, NN)\n",
        "y_test_np = Var_to_nparray(y_test)\n",
        "plt.scatter(y_test_np, Var_to_nparray(output_test));\n",
        "plt.plot([np.min(y_test_np), np.max(y_test_np)], [np.min(y_test_np), np.max(y_test_np)], color='k');\n",
        "plt.xlabel(\"y\");\n",
        "plt.ylabel(\"$\\hat{y}$\");\n",
        "plt.title(\"Model prediction vs real in the test set, the closer to the line the better\")\n",
        "plt.grid(True);\n",
        "plt.axis('equal');\n",
        "plt.tight_layout();\n",
        "\n",
        "Loss_test = squared_loss(y_test, forward(x_test, NN))\n",
        "\n",
        "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))"
      ],
      "metadata": {
        "id": "eXwdT8Xj3Bsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Underfitting"
      ],
      "metadata": {
        "id": "OCQxKwmt3sVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Underfitting\n",
        "NN = [\n",
        "    DenseLayer(1, 2, lambda x: x.tanh()),\n",
        "    DenseLayer(2, 1, lambda x: x.relu())\n",
        "]\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "# Initialize training hyperparameters\n",
        "EPOCHS = 100\n",
        "LEARN_R = 2e-3 \n",
        "\n",
        "for e in range(EPOCHS):\n",
        "     \n",
        "    # Forward pass and loss computation\n",
        "    Loss = squared_loss(y_train, forward(x_train, NN))\n",
        "\n",
        "    # Backward pass\n",
        "    Loss.backward()\n",
        "    \n",
        "    # gradient descent update\n",
        "    update_parameters(parameters(NN), LEARN_R)\n",
        "    zero_gradients(parameters(NN))\n",
        "    \n",
        "    # Training loss\n",
        "    train_loss.append(Loss.v)\n",
        "    \n",
        "    # Validation\n",
        "    Loss_validation = squared_loss(y_validation, forward(x_validation, NN))\n",
        "    val_loss.append(Loss_validation.v)\n",
        "    \n",
        "    if e%10==0:\n",
        "        print(\"{:4d}\".format(e),\n",
        "              \"({:5.2f}%)\".format(e/EPOCHS*100), \n",
        "              \"Train loss: {:4.3f} \\t Validation loss: {:4.3f}\".format(train_loss[-1], val_loss[-1]))"
      ],
      "metadata": {
        "id": "tp14P5jr3v1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(train_loss)), train_loss);\n",
        "plt.plot(range(len(val_loss)), val_loss);\n",
        "plt.legend(loc=1, fontsize=16, labels = [\"Training loss\", \"Validation loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJZTWDbM3zsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_test = forward(x_test, NN)\n",
        "y_test_np = Var_to_nparray(y_test)\n",
        "plt.scatter(y_test_np, Var_to_nparray(output_test));\n",
        "plt.plot([np.min(y_test_np), np.max(y_test_np)], [np.min(y_test_np), np.max(y_test_np)], color='k');\n",
        "plt.xlabel(\"y\");\n",
        "plt.ylabel(\"$\\hat{y}$\");\n",
        "plt.title(\"Model prediction vs real in the test set, the closer to the line the better\")\n",
        "plt.grid(True);\n",
        "plt.axis('equal');\n",
        "plt.tight_layout();\n",
        "\n",
        "Loss_test = squared_loss(y_test, forward(x_test, NN))\n",
        "\n",
        "print(\"Test loss:  {:4.3f}\".format(Loss_test.v))"
      ],
      "metadata": {
        "id": "voGdRNNd330f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYPZP-eTFtIo"
      },
      "source": [
        "# Next steps - classification\n",
        "\n",
        "It is straight forward to extend what we have done to classification. \n",
        "\n",
        "For numerical stability it is better to make softmax and cross-entropy as one function so we write the cross entropy loss as a function of the logits we talked about last week. \n",
        "\n",
        "Next week we will see how to perform classification in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsVPul3QFtIo"
      },
      "source": [
        "## Exercise m) optional - Implement backpropagation for classification\n",
        "\n",
        "Should be possible with very few lines of code. :-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC8QrI2tFtIp"
      },
      "outputs": [],
      "source": [
        "# Just add code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APqhJv3tta1O"
      },
      "source": [
        "## Exercise n) optional - Introduce a NeuralNetwork class\n",
        "\n",
        "The functions we applied on the neural network (parameters, update_parameters and zero_gradients) can more naturally be included as methods in a NeuralNetwork class. Make such a class and modify the code to use it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqfnor1ouMLq"
      },
      "outputs": [],
      "source": [
        "# just add some code"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [
        "U4057_ljNvWB",
        "p_8n_SKnIW2F",
        "oLrGJytZFtGm",
        "jpIZPBpNI0pO",
        "_79HOAXrFtHK",
        "mqeyab9qFtGs",
        "-XyXBD37FtHk",
        "SrwSJ2UWFtHu",
        "zTBAmjsAFtIk",
        "qsVPul3QFtIo",
        "APqhJv3tta1O"
      ],
      "name": "2.1-EXE-FNN-AutoDif-Nanograd.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}